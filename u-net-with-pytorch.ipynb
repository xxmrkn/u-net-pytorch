{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport copy\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import Adam\n\n\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\n#import torchvision.transforms.functional as F\n#from torchvision.datasets import OxfordIIITPet\n\nfrom PIL import Image\nimport io\nfrom io import BytesIO \n\nimport cv2\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout,GridDropout\n    )\n\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import Image as Im\nfrom PIL import ImageOps\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"2hbZj8CKoAc-","execution":{"iopub.status.busy":"2022-04-11T00:16:22.408336Z","iopub.execute_input":"2022-04-11T00:16:22.408696Z","iopub.status.idle":"2022-04-11T00:16:30.635531Z","shell.execute_reply.started":"2022-04-11T00:16:22.408596Z","shell.execute_reply":"2022-04-11T00:16:30.634797Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":" class CFG:\n        BASE_PATH = '../input/oxfordiiitpet-dataset/'\n        IMAGE_PATH = '../input/oxfordiiitpet-dataset/images/images/'\n        ANNOTATION_PATH = '../input/oxfordiiitpet-dataset/annotations/annotations/'\n        \n        DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        IMAGE_SIZE = 128\n        BATCH_SIZE = 32\n        \n        def to_numpy(tensor):\n            return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.637266Z","iopub.execute_input":"2022-04-11T00:16:30.637641Z","iopub.status.idle":"2022-04-11T00:16:30.652370Z","shell.execute_reply.started":"2022-04-11T00:16:30.637605Z","shell.execute_reply":"2022-04-11T00:16:30.651729Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Create DataFrame","metadata":{}},{"cell_type":"code","source":"all_df = pd.read_table(CFG.ANNOTATION_PATH+'list.txt',sep=' ',skiprows=5 )\nall_df = all_df.iloc[:,:4]\nall_df = all_df.set_axis(['image_name','id','species','breed'],axis=1)\nall_df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.655085Z","iopub.execute_input":"2022-04-11T00:16:30.655487Z","iopub.status.idle":"2022-04-11T00:16:30.714370Z","shell.execute_reply.started":"2022-04-11T00:16:30.655453Z","shell.execute_reply":"2022-04-11T00:16:30.713743Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\nif DEBUG:\n    all_df = all_df.sample(frac = 0.3).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.716209Z","iopub.execute_input":"2022-04-11T00:16:30.716442Z","iopub.status.idle":"2022-04-11T00:16:30.720806Z","shell.execute_reply.started":"2022-04-11T00:16:30.716410Z","shell.execute_reply":"2022-04-11T00:16:30.719930Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"all_df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.722108Z","iopub.execute_input":"2022-04-11T00:16:30.725132Z","iopub.status.idle":"2022-04-11T00:16:30.736710Z","shell.execute_reply.started":"2022-04-11T00:16:30.723327Z","shell.execute_reply":"2022-04-11T00:16:30.735952Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Split train and validation 8:2","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(all_df, test_size = 0.2)\nprint(train_df.shape, valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.738101Z","iopub.execute_input":"2022-04-11T00:16:30.738347Z","iopub.status.idle":"2022-04-11T00:16:30.746460Z","shell.execute_reply.started":"2022-04-11T00:16:30.738315Z","shell.execute_reply":"2022-04-11T00:16:30.745429Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.747524Z","iopub.execute_input":"2022-04-11T00:16:30.749169Z","iopub.status.idle":"2022-04-11T00:16:30.761805Z","shell.execute_reply.started":"2022-04-11T00:16:30.749133Z","shell.execute_reply":"2022-04-11T00:16:30.760998Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"valid_df = valid_df.reset_index(drop=True)\nvalid_df","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.762995Z","iopub.execute_input":"2022-04-11T00:16:30.763297Z","iopub.status.idle":"2022-04-11T00:16:30.777074Z","shell.execute_reply.started":"2022-04-11T00:16:30.763263Z","shell.execute_reply":"2022-04-11T00:16:30.776405Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Visualize images","metadata":{}},{"cell_type":"code","source":"#nomal images\nimage = Im.open(CFG.IMAGE_PATH+all_df[\"image_name\"][0]+\".jpg\")\n#image = Im.open('../input/oxfordiiitpet-dataset/images/images/Abyssinian_10.jpg')\ndisplay(image)\ni = np.array(image)\ni.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.778127Z","iopub.execute_input":"2022-04-11T00:16:30.778492Z","iopub.status.idle":"2022-04-11T00:16:30.890427Z","shell.execute_reply.started":"2022-04-11T00:16:30.778456Z","shell.execute_reply":"2022-04-11T00:16:30.889731Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#mask image\n#mask_image = PIL.ImageOps.autocontrast(load_img('../input/oxfordiiitpet-dataset/annotations/annotations/trimaps/Abyssinian_10.png'))\nmask_image = PIL.ImageOps.autocontrast(load_img(CFG.ANNOTATION_PATH+'trimaps/'+all_df[\"image_name\"][0]+'.png'))\ndisplay(mask_image)\nrgb2gry = transforms.Grayscale()\nmask_images = mask_image.convert('L')\n#mask_image = mask_image.transpose(1,0,2)\nmask = np.array(mask_image)\n#print(mask)\n#mask = mask.transpose(1,0,2)\n\nobj_ids = np.unique(mask)\nprint(obj_ids)\n\n# convert [0,127,255] to [0,1,2]\nmask[mask == 0] = 1\nmask[mask == 127] = 0\nmask[mask == 255] = 1\n#print(mask)\nprint(np.unique(mask))\n#obj_ids[:]\n#masks = mask == obj_ids[:,None,None]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.893046Z","iopub.execute_input":"2022-04-11T00:16:30.893290Z","iopub.status.idle":"2022-04-11T00:16:30.945557Z","shell.execute_reply.started":"2022-04-11T00:16:30.893257Z","shell.execute_reply":"2022-04-11T00:16:30.944864Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"print(type(image))\nprint(type(mask_image))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.946640Z","iopub.execute_input":"2022-04-11T00:16:30.947095Z","iopub.status.idle":"2022-04-11T00:16:30.951816Z","shell.execute_reply.started":"2022-04-11T00:16:30.947059Z","shell.execute_reply":"2022-04-11T00:16:30.951179Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# image and mask","metadata":{}},{"cell_type":"code","source":"def get_concat_h(im1, im2):\n    dst = Im.new('RGB', (im1.width + im2.width, im1.height))\n    dst.paste(im1, (0, 0))\n    dst.paste(im2, (im1.width, 0))\n    return dst\n\nget_concat_h(image, mask_image)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:30.952844Z","iopub.execute_input":"2022-04-11T00:16:30.953734Z","iopub.status.idle":"2022-04-11T00:16:31.034588Z","shell.execute_reply.started":"2022-04-11T00:16:30.953692Z","shell.execute_reply":"2022-04-11T00:16:31.034021Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation function","metadata":{}},{"cell_type":"code","source":"def get_transform(data):\n    if data == 'train':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.HorizontalFlip(p=0.5),\n                #A.GridDropout(ratio=0.2, unit_size_min=None, unit_size_max=None, holes_number_x=5, holes_number_y=5, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5),\n                A.Normalize(),\n                ToTensorV2()\n            ])\n    elif data == 'valid':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.Normalize(),\n                ToTensorV2()\n            ])","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.035612Z","iopub.execute_input":"2022-04-11T00:16:31.035950Z","iopub.status.idle":"2022-04-11T00:16:31.042083Z","shell.execute_reply.started":"2022-04-11T00:16:31.035920Z","shell.execute_reply":"2022-04-11T00:16:31.041388Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"len(all_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.043355Z","iopub.execute_input":"2022-04-11T00:16:31.044021Z","iopub.status.idle":"2022-04-11T00:16:31.053634Z","shell.execute_reply.started":"2022-04-11T00:16:31.043989Z","shell.execute_reply":"2022-04-11T00:16:31.052896Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#confirm path for dataset class\nimage_path = CFG.IMAGE_PATH\nmask_path = CFG.ANNOTATION_PATH\nprint(os.path.join(image_path, all_df[\"image_name\"][0]+'.jpg'))\nprint(os.path.join(mask_path, 'trimaps/'+all_df[\"image_name\"][0]+'.png'))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.054905Z","iopub.execute_input":"2022-04-11T00:16:31.055604Z","iopub.status.idle":"2022-04-11T00:16:31.062594Z","shell.execute_reply.started":"2022-04-11T00:16:31.055568Z","shell.execute_reply":"2022-04-11T00:16:31.061715Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, df, transforms=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.df = df\n        self.image_names = df[\"image_name\"]\n        self.transforms = transforms\n        \n    def __len__(self):\n        #print(len(self.df))\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        # get path\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.image_paths, image_name+'.jpg')\n        mask_path = os.path.join(self.mask_paths, 'trimaps/'+image_name+'.png')\n        #print(image_path,mask_path)\n        #open image\n        image = Im.open(image_path)\n        mask_images = PIL.ImageOps.autocontrast(load_img(mask_path))\n        rgb2gry = transforms.Grayscale()\n        mask_images = rgb2gry(mask_images)\n        #PIL to numpy\n        image = np.array(image)\n        image = image[:,:,:3]#remove some of alpha channels\n        mask_images = np.array(mask_images)\n        #convert [0,127,255] -> [0,1,2]\n        mask_images[mask_images == 127] = 1\n        mask_images[mask_images == 255] = 2\n\n        obj_ids = np.unique(mask_images)\n        \n        if self.transforms:\n            augmented = self.transforms(image=image,mask=mask_images)\n            image,mask = augmented['image'],augmented['mask']\n\n        mask  = mask.unsqueeze(0)\n\n        return image,mask","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.064059Z","iopub.execute_input":"2022-04-11T00:16:31.064521Z","iopub.status.idle":"2022-04-11T00:16:31.076277Z","shell.execute_reply.started":"2022-04-11T00:16:31.064486Z","shell.execute_reply":"2022-04-11T00:16:31.075592Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    train_df,\n    transforms = get_transform(data='train'),\n)\nvalid_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    valid_df,\n    transforms = get_transform(data='valid'),\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.077560Z","iopub.execute_input":"2022-04-11T00:16:31.078020Z","iopub.status.idle":"2022-04-11T00:16:31.086644Z","shell.execute_reply.started":"2022-04-11T00:16:31.077988Z","shell.execute_reply":"2022-04-11T00:16:31.085769Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# CPUのコア数を確認\nimport os\nos.cpu_count()  # コア数","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.087800Z","iopub.execute_input":"2022-04-11T00:16:31.088577Z","iopub.status.idle":"2022-04-11T00:16:31.096688Z","shell.execute_reply.started":"2022-04-11T00:16:31.088537Z","shell.execute_reply":"2022-04-11T00:16:31.095939Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True)\ntrain_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.098969Z","iopub.execute_input":"2022-04-11T00:16:31.099411Z","iopub.status.idle":"2022-04-11T00:16:31.216660Z","shell.execute_reply.started":"2022-04-11T00:16:31.099374Z","shell.execute_reply":"2022-04-11T00:16:31.215951Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"valid_loader = DataLoader(valid_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True)\nvalid_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.218022Z","iopub.execute_input":"2022-04-11T00:16:31.218301Z","iopub.status.idle":"2022-04-11T00:16:31.254068Z","shell.execute_reply.started":"2022-04-11T00:16:31.218265Z","shell.execute_reply":"2022-04-11T00:16:31.253342Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Define U-Net model","metadata":{}},{"cell_type":"markdown","source":"## part of U-Net models","metadata":{}},{"cell_type":"markdown","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        self.conv = DoubleConv(in_channels, out_channels)\n        \n    def forward(self, x1,x2):\n        x1 = self.up(x1)\n        \n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX // 2, diffX - diffX //2,\n                        diffY // 2, diffY - diffY //2])\n        \n        x = torch.cat([x2,x1],dim=1)\n        return self.conv(x)\n    \nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:25:54.165805Z","iopub.execute_input":"2022-04-10T22:25:54.166368Z","iopub.status.idle":"2022-04-10T22:25:54.180453Z","shell.execute_reply.started":"2022-04-10T22:25:54.166328Z","shell.execute_reply":"2022-04-10T22:25:54.179505Z"}}},{"cell_type":"code","source":"#pytorch official\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1,bias=False),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n        #self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        #self.conv = DoubleConv(in_channels, out_channels)\n        \n    def forward(self, x1,x2):\n        x1 = self.up(x1)\n        \n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX // 2, diffX - diffX //2,\n                        diffY // 2, diffY - diffY //2])\n        \n        x = torch.cat([x2,x1],dim=1)\n        return self.conv(x)\n    \nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.255373Z","iopub.execute_input":"2022-04-11T00:16:31.255743Z","iopub.status.idle":"2022-04-11T00:16:31.270263Z","shell.execute_reply.started":"2022-04-11T00:16:31.255710Z","shell.execute_reply":"2022-04-11T00:16:31.269600Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## main part of U-Net","metadata":{}},{"cell_type":"markdown","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64,128)\n        self.down2 = Down(128,256)\n        self.down3 = Down(256,512)\n        self.down4 = Down(512,1024)\n        self.up1 = Up(1024,512)\n        self.up2 = Up(512,256)\n        self.up3 = Up(256,128)\n        self.up4 = Up(128,64)\n        self.outc = OutConv(64,n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5,x4)\n        x = self.up2(x,x3)\n        x = self.up3(x,x2)\n        x = self.up4(x,x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:25:54.182234Z","iopub.execute_input":"2022-04-10T22:25:54.182697Z","iopub.status.idle":"2022-04-10T22:25:54.192975Z","shell.execute_reply.started":"2022-04-10T22:25:54.182659Z","shell.execute_reply":"2022-04-10T22:25:54.192197Z"}}},{"cell_type":"code","source":"#pytorch official\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes,bilinear=False):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64,128)\n        self.down2 = Down(128,256)\n        self.down3 = Down(256,512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512,1024 // factor)\n        self.up1 = Up(1024,512 // factor, bilinear)\n        self.up2 = Up(512,256 // factor, bilinear)\n        self.up3 = Up(256,128 // factor, bilinear)\n        self.up4 = Up(128,64, bilinear)\n        self.outc = OutConv(64,n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5,x4)\n        x = self.up2(x,x3)\n        x = self.up3(x,x2)\n        x = self.up4(x,x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.271614Z","iopub.execute_input":"2022-04-11T00:16:31.271997Z","iopub.status.idle":"2022-04-11T00:16:31.283020Z","shell.execute_reply.started":"2022-04-11T00:16:31.271945Z","shell.execute_reply":"2022-04-11T00:16:31.282289Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Custom metrics","metadata":{}},{"cell_type":"code","source":"def Dice_Coeff(x,y):\n    \n    #x:predmask, y:truemask\n    x = CFG.to_numpy(x)\n    y = CFG.to_numpy(y)\n    x[x==2] = 0\n    y[y==2] = 0\n    \n    x = torch.tensor(x)\n    y = torch.tensor(y)\n    \n    intersection = torch.sum(x&y)\n    \n    dice = (2*intersection)/(CFG.IMAGE_SIZE*CFG.IMAGE_SIZE*CFG.BATCH_SIZE + CFG.IMAGE_SIZE*CFG.IMAGE_SIZE*CFG.BATCH_SIZE)\n\n    return dice","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.285680Z","iopub.execute_input":"2022-04-11T00:16:31.286151Z","iopub.status.idle":"2022-04-11T00:16:31.293014Z","shell.execute_reply.started":"2022-04-11T00:16:31.286112Z","shell.execute_reply":"2022-04-11T00:16:31.292268Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Visualize image (input and mask)","metadata":{}},{"cell_type":"code","source":"def show_pred_mask(original,true_tensor,out_tensor,cnt):\n        unnormalize = transforms.Normalize(\n        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n        std=[1/0.229, 1/0.224, 1/0.255]\n        )\n        original = unnormalize(original)\n\n        y = CFG.to_numpy(true_tensor)\n        z = CFG.to_numpy(out_tensor)\n\n        original = original.permute(2,1,0)\n        original = CFG.to_numpy(original)\n        original = np.rot90(original)\n        original = np.flipud(original)\n\n        y[y==0] = 255\n        y[y==1] = 127\n        y[y==2] = 0\n\n        z[z==0] = 255\n        z[z==1] = 127\n        z[z==2] = 0\n\n        n_data = 3\n        row=1\n        col=3\n        fig, ax = plt.subplots(nrows=row, ncols=col,figsize=(15,18))\n\n        #input image\n        ax[0].imshow(original)\n\n        #truth mask\n        ax[1].imshow(y,cmap='Greys')\n\n        #pred mask\n        ax[2].imshow(z,cmap='Greys')\n\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.294124Z","iopub.execute_input":"2022-04-11T00:16:31.294725Z","iopub.status.idle":"2022-04-11T00:16:31.304574Z","shell.execute_reply.started":"2022-04-11T00:16:31.294680Z","shell.execute_reply":"2022-04-11T00:16:31.303852Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"plot_train_loss = []\nplot_train_dice = []\n\nplot_valid_loss = []\nplot_valid_dice = []\n\nL_t = []\nD_t = []\nL_v = []\nD_v = []\n\ndef training_model(model, datasets, dataloaders, criterion, optimizer, num_epochs, device):\n    best_model_weights = copy.deepcopy(model.state_dict())\n    best_dice = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print('-'*10)\n        \n        for phase in ['train','valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_loss = 0.0\n            running_dice = 0.0\n            \n            stream = tqdm(dataloaders[phase])\n            for cnt, (inputs, masks) in enumerate(stream, start=1):\n\n                original = inputs\n                inputs = inputs.to(device=CFG.DEVICE, dtype=torch.float32)\n                masks = masks.to(device=CFG.DEVICE, dtype=torch.long)\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase=='train'):\n                    model = model.to(CFG.DEVICE)\n                    outputs = model(inputs)\n                    \n                    pred_masks = F.softmax(outputs, dim=1).float()\n                    masks =  masks.squeeze(1)\n                    loss = criterion(pred_masks, masks)#CrossEntropyLoss\n                    _,ch = torch.max(outputs, -3)\n                    dice = Dice_Coeff(ch, masks)\n\n                    running_loss += loss.item()\n                    running_dice += dice\n                    \n                    if phase =='train':\n                        L_t.append(loss.item())\n                        D_t.append(dice)\n                    else:\n                        L_v.append(loss.item())\n                        D_v.append(dice)\n\n                    if cnt-1 == 0:\n                        show_pred_mask(original[0],masks[0],ch[0],cnt)\n                        show_pred_mask(original[1],masks[1],ch[1],cnt)\n                    else:\n                        continue\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n            epoch_loss = running_loss/len(dataloaders[phase])\n            epoch_dice = running_dice/len(dataloaders[phase])\n            \n            if phase == 'train':\n                plot_train_loss.append(epoch_loss)\n                plot_train_dice.append(epoch_dice)\n            else:\n                plot_valid_loss.append(epoch_loss)\n                plot_valid_dice.append(epoch_dice)\n            \n            print(f'{phase} Loss: {epoch_loss} Dice: {epoch_dice}')\n            \n            #if phase == 'valid' and epoch_dice > best_dice:\n                #best_dice = epoch_dice\n                #best_model_weights = copy().deepcopy(model.state_dict())\n                \n        print()\n        \n    #print(f'Best val Dice:{best_dice}')\n          \n    #model.load_state_dict(best_model_weights)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.305724Z","iopub.execute_input":"2022-04-11T00:16:31.306486Z","iopub.status.idle":"2022-04-11T00:16:31.323451Z","shell.execute_reply.started":"2022-04-11T00:16:31.306451Z","shell.execute_reply":"2022-04-11T00:16:31.322636Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"datasets = {'train': train_dataset,\n            'valid': valid_dataset}\n\ndataloaders = {'train': train_loader,\n               'valid': valid_loader}\nmodel = UNet(n_channels=3, n_classes=3)\n#optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\nnum_epochs = 30","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.324859Z","iopub.execute_input":"2022-04-11T00:16:31.325376Z","iopub.status.idle":"2022-04-11T00:16:31.599944Z","shell.execute_reply.started":"2022-04-11T00:16:31.325321Z","shell.execute_reply":"2022-04-11T00:16:31.599207Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"trained_model = training_model(model,datasets, dataloaders, criterion, optimizer, num_epochs, CFG.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:16:31.601384Z","iopub.execute_input":"2022-04-11T00:16:31.601629Z","iopub.status.idle":"2022-04-11T00:53:21.964789Z","shell.execute_reply.started":"2022-04-11T00:16:31.601596Z","shell.execute_reply":"2022-04-11T00:53:21.964011Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"len(L_t),len(D_t)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:53:21.969235Z","iopub.execute_input":"2022-04-11T00:53:21.969454Z","iopub.status.idle":"2022-04-11T00:53:21.975452Z","shell.execute_reply.started":"2022-04-11T00:53:21.969428Z","shell.execute_reply":"2022-04-11T00:53:21.974513Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"len(L_v),len(D_v)","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:53:21.977409Z","iopub.execute_input":"2022-04-11T00:53:21.977712Z","iopub.status.idle":"2022-04-11T00:53:21.988680Z","shell.execute_reply.started":"2022-04-11T00:53:21.977670Z","shell.execute_reply":"2022-04-11T00:53:21.987766Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(L_t, num_epochs)))\nplt.title('Loss')\nplt.ylabel('loss')\nplt.ylim([0.7, 1.2])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:53:58.403093Z","iopub.execute_input":"2022-04-11T00:53:58.403679Z","iopub.status.idle":"2022-04-11T00:53:59.248555Z","shell.execute_reply.started":"2022-04-11T00:53:58.403644Z","shell.execute_reply":"2022-04-11T00:53:59.247874Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(D_t, num_epochs)))\nplt.title('Dice')\nplt.ylabel('dice')\nplt.ylim([0, 0.7])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:54:23.952652Z","iopub.execute_input":"2022-04-11T00:54:23.952903Z","iopub.status.idle":"2022-04-11T00:54:24.509619Z","shell.execute_reply.started":"2022-04-11T00:54:23.952875Z","shell.execute_reply":"2022-04-11T00:54:24.508896Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"tensorx = torch.tensor([[[1,0,1,1],[1,1,1,1],[1,0,0,1],[1,1,0,0]],[[1,0,1,0],[0,0,1,1],[0,0,0,1],[0,1,0,0]]])\ntensory = torch.tensor([[[1,0,0,1],[1,0,0,1],[1,1,0,1],[1,0,0,0]],[[0,1,0,1],[0,1,0,1],[0,1,1,1],[1,0,0,0]]])\n#tensorx = CFG.to_numpy(tensorx)\n#tensory = CFG.to_numpy(tensory)\nprint(tensorx.shape,tensory.shape)\nprint(torch.sum(tensorx & tensory))\n#print((torch.matmul(tensorx,tensory)).shape)\n#print(sum(torch.matmul(tensorx,tensory)))\n#print((sum(torch.matmul(tensorx,tensory))).shape)\n#print(torch.sum(torch.matmul(tensorx,tensory)))\n\nprint(torch.sum(tensorx),torch.sum(tensory))\n\nprint((2*torch.sum(tensorx & tensory))/(4*4*2+4*4*2))","metadata":{"execution":{"iopub.status.busy":"2022-04-11T00:53:23.137713Z","iopub.execute_input":"2022-04-11T00:53:23.138224Z","iopub.status.idle":"2022-04-11T00:53:23.150064Z","shell.execute_reply.started":"2022-04-11T00:53:23.138184Z","shell.execute_reply":"2022-04-11T00:53:23.149241Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}