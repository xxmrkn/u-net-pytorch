{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport copy\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import Adam\n\n\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\n#import torchvision.transforms.functional as F\n#from torchvision.datasets import OxfordIIITPet\n\nfrom PIL import Image\nimport io\nfrom io import BytesIO \n\nimport cv2\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout,GridDropout\n    )\n\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import Image as Im\nfrom PIL import ImageOps\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"2hbZj8CKoAc-","execution":{"iopub.status.busy":"2022-04-23T04:38:19.521937Z","iopub.execute_input":"2022-04-23T04:38:19.522735Z","iopub.status.idle":"2022-04-23T04:38:27.767770Z","shell.execute_reply.started":"2022-04-23T04:38:19.522618Z","shell.execute_reply":"2022-04-23T04:38:27.767016Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":" class CFG:\n        BASE_PATH = '../input/oxfordiiitpet-dataset/'\n        IMAGE_PATH = '../input/oxfordiiitpet-dataset/images/images/'\n        ANNOTATION_PATH = '../input/oxfordiiitpet-dataset/annotations/annotations/'\n        \n        DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        IMAGE_SIZE = 128\n        BATCH_SIZE = 64\n        \n        def to_numpy(tensor):\n            return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.769471Z","iopub.execute_input":"2022-04-23T04:38:27.769891Z","iopub.status.idle":"2022-04-23T04:38:27.786843Z","shell.execute_reply.started":"2022-04-23T04:38:27.769839Z","shell.execute_reply":"2022-04-23T04:38:27.785780Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Create DataFrame","metadata":{}},{"cell_type":"code","source":"all_df = pd.read_table(CFG.ANNOTATION_PATH+'list.txt',sep=' ',skiprows=5 )\nall_df = all_df.iloc[:,:4]\nall_df = all_df.set_axis(['image_name','id','species','breed'],axis=1)\nall_df","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.790186Z","iopub.execute_input":"2022-04-23T04:38:27.790652Z","iopub.status.idle":"2022-04-23T04:38:27.837484Z","shell.execute_reply.started":"2022-04-23T04:38:27.790617Z","shell.execute_reply":"2022-04-23T04:38:27.836819Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"all_df.groupby(\"id\").count()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.839265Z","iopub.execute_input":"2022-04-23T04:38:27.839905Z","iopub.status.idle":"2022-04-23T04:38:27.857568Z","shell.execute_reply.started":"2022-04-23T04:38:27.839851Z","shell.execute_reply":"2022-04-23T04:38:27.856938Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\nif DEBUG:\n    all_df = all_df.sample(frac = 0.5).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.858694Z","iopub.execute_input":"2022-04-23T04:38:27.859073Z","iopub.status.idle":"2022-04-23T04:38:27.863063Z","shell.execute_reply.started":"2022-04-23T04:38:27.859041Z","shell.execute_reply":"2022-04-23T04:38:27.862394Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"all_df","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.864404Z","iopub.execute_input":"2022-04-23T04:38:27.864783Z","iopub.status.idle":"2022-04-23T04:38:27.877681Z","shell.execute_reply.started":"2022-04-23T04:38:27.864750Z","shell.execute_reply":"2022-04-23T04:38:27.877071Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Split train and validation 7:3","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(all_df, test_size = 0.3)\nprint(train_df.shape, valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.878889Z","iopub.execute_input":"2022-04-23T04:38:27.879131Z","iopub.status.idle":"2022-04-23T04:38:27.888283Z","shell.execute_reply.started":"2022-04-23T04:38:27.879098Z","shell.execute_reply":"2022-04-23T04:38:27.887572Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.889392Z","iopub.execute_input":"2022-04-23T04:38:27.889672Z","iopub.status.idle":"2022-04-23T04:38:27.906381Z","shell.execute_reply.started":"2022-04-23T04:38:27.889637Z","shell.execute_reply":"2022-04-23T04:38:27.905807Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"valid_df = valid_df.reset_index(drop=True)\nvalid_df","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.908950Z","iopub.execute_input":"2022-04-23T04:38:27.909940Z","iopub.status.idle":"2022-04-23T04:38:27.923120Z","shell.execute_reply.started":"2022-04-23T04:38:27.909411Z","shell.execute_reply":"2022-04-23T04:38:27.922374Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Visualize images","metadata":{}},{"cell_type":"code","source":"#nomal images\nimage = Im.open(CFG.IMAGE_PATH+all_df[\"image_name\"][0]+\".jpg\")\n#image = Im.open('../input/oxfordiiitpet-dataset/images/images/Abyssinian_10.jpg')\ndisplay(image)\ni = np.array(image)\ni.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:27.926958Z","iopub.execute_input":"2022-04-23T04:38:27.928491Z","iopub.status.idle":"2022-04-23T04:38:28.041635Z","shell.execute_reply.started":"2022-04-23T04:38:27.928465Z","shell.execute_reply":"2022-04-23T04:38:28.040932Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#mask image\n#mask_image = PIL.ImageOps.autocontrast(load_img('../input/oxfordiiitpet-dataset/annotations/annotations/trimaps/Abyssinian_10.png'))\nmask_image = PIL.ImageOps.autocontrast(load_img(CFG.ANNOTATION_PATH+'trimaps/'+all_df[\"image_name\"][0]+'.png'))\ndisplay(mask_image)\nrgb2gry = transforms.Grayscale()\nmask_images = mask_image.convert('L')\n#mask_image = mask_image.transpose(1,0,2)\n\nmask = np.array(mask_image)\nprint(mask.shape)\n#mask = mask.transpose(1,0,2)\n\nobj_ids = np.unique(mask)\nprint(obj_ids)\n\n# convert [0,127,255] to [0,1,2]\nmask[mask == 0] = 1\nmask[mask == 127] = 0\nmask[mask == 255] = 1\nprint(mask)\nprint(np.unique(mask))\n#obj_ids[:]\n#masks = mask == obj_ids[:,None,None]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.042606Z","iopub.execute_input":"2022-04-23T04:38:28.042842Z","iopub.status.idle":"2022-04-23T04:38:28.092685Z","shell.execute_reply.started":"2022-04-23T04:38:28.042811Z","shell.execute_reply":"2022-04-23T04:38:28.091981Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"print(type(image))\nprint(type(mask_image))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.094064Z","iopub.execute_input":"2022-04-23T04:38:28.094310Z","iopub.status.idle":"2022-04-23T04:38:28.100265Z","shell.execute_reply.started":"2022-04-23T04:38:28.094277Z","shell.execute_reply":"2022-04-23T04:38:28.099543Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# image and mask","metadata":{}},{"cell_type":"code","source":"def get_concat_h(im1, im2):\n    dst = Im.new('RGB', (im1.width + im2.width, im1.height))\n    dst.paste(im1, (0, 0))\n    dst.paste(im2, (im1.width, 0))\n    return dst\n\nget_concat_h(image, mask_image)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.101533Z","iopub.execute_input":"2022-04-23T04:38:28.102336Z","iopub.status.idle":"2022-04-23T04:38:28.182956Z","shell.execute_reply.started":"2022-04-23T04:38:28.102302Z","shell.execute_reply":"2022-04-23T04:38:28.182136Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation function","metadata":{}},{"cell_type":"code","source":"def get_transform(data):\n    if data == 'train':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.HorizontalFlip(p=0.5),\n                #A.GridDropout(ratio=0.2, unit_size_min=None, unit_size_max=None, holes_number_x=5, holes_number_y=5, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5),\n                A.Normalize(),\n                ToTensorV2()\n            ])\n    elif data == 'valid':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.Normalize(),\n                ToTensorV2()\n            ])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.184189Z","iopub.execute_input":"2022-04-23T04:38:28.184483Z","iopub.status.idle":"2022-04-23T04:38:28.191787Z","shell.execute_reply.started":"2022-04-23T04:38:28.184449Z","shell.execute_reply":"2022-04-23T04:38:28.190797Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"len(all_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.193491Z","iopub.execute_input":"2022-04-23T04:38:28.193787Z","iopub.status.idle":"2022-04-23T04:38:28.206625Z","shell.execute_reply.started":"2022-04-23T04:38:28.193751Z","shell.execute_reply":"2022-04-23T04:38:28.205857Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#confirm path for dataset class\nimage_path = CFG.IMAGE_PATH\nmask_path = CFG.ANNOTATION_PATH\nprint(os.path.join(image_path, all_df[\"image_name\"][0]+'.jpg'))\nprint(os.path.join(mask_path, 'trimaps/'+all_df[\"image_name\"][0]+'.png'))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.208138Z","iopub.execute_input":"2022-04-23T04:38:28.208627Z","iopub.status.idle":"2022-04-23T04:38:28.215714Z","shell.execute_reply.started":"2022-04-23T04:38:28.208592Z","shell.execute_reply":"2022-04-23T04:38:28.214997Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, df, transforms=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.df = df\n        self.image_names = df[\"image_name\"]\n        self.transforms = transforms\n        \n    def __len__(self):\n        #print(len(self.df))\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        # get path\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.image_paths, image_name+'.jpg')\n        mask_path = os.path.join(self.mask_paths, 'trimaps/'+image_name+'.png')\n        #print(image_path,mask_path)\n        #open image\n        image = Im.open(image_path)\n        mask_images = PIL.ImageOps.autocontrast(load_img(mask_path))\n        rgb2gry = transforms.Grayscale()\n        mask_images = rgb2gry(mask_images)\n        #PIL to numpy\n        image = np.array(image)\n        image = image[:,:,:3]#remove some of alpha channels\n\n        mask_images = np.array(mask_images)\n\n        #convert [0,127,255] -> [0,1,2] #0が黒→物体内部、127がグレー→背景、255が白→物体輪郭\n        mask_images[mask_images == 0] = 0\n        mask_images[mask_images == 127] = 1\n        mask_images[mask_images == 255] = 2\n        #print(mask_images)\n\n        obj_ids = np.unique(mask_images)\n        \n        if self.transforms:\n            augmented = self.transforms(image=image,mask=mask_images)\n            image,mask = augmented['image'],augmented['mask']\n            #print(image.shape,mask.shape)\n\n        mask  = mask.unsqueeze(0)\n\n\n        return image,mask, image_path, mask_path","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.217239Z","iopub.execute_input":"2022-04-23T04:38:28.217844Z","iopub.status.idle":"2022-04-23T04:38:28.229315Z","shell.execute_reply.started":"2022-04-23T04:38:28.217686Z","shell.execute_reply":"2022-04-23T04:38:28.228587Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    train_df,\n    transforms = get_transform(data='train'),\n)\nvalid_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    valid_df,\n    transforms = get_transform(data='valid'),\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.230666Z","iopub.execute_input":"2022-04-23T04:38:28.231151Z","iopub.status.idle":"2022-04-23T04:38:28.242010Z","shell.execute_reply.started":"2022-04-23T04:38:28.231118Z","shell.execute_reply":"2022-04-23T04:38:28.241184Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# CPUのコア数を確認\nimport os\nos.cpu_count()  # コア数","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.243346Z","iopub.execute_input":"2022-04-23T04:38:28.243591Z","iopub.status.idle":"2022-04-23T04:38:28.252677Z","shell.execute_reply.started":"2022-04-23T04:38:28.243559Z","shell.execute_reply":"2022-04-23T04:38:28.251935Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True,drop_last=True)\ntrain_dataset[0][2:]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.254032Z","iopub.execute_input":"2022-04-23T04:38:28.254276Z","iopub.status.idle":"2022-04-23T04:38:28.303766Z","shell.execute_reply.started":"2022-04-23T04:38:28.254245Z","shell.execute_reply":"2022-04-23T04:38:28.303120Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"valid_loader = DataLoader(valid_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True,drop_last=True)\nvalid_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.305031Z","iopub.execute_input":"2022-04-23T04:38:28.305418Z","iopub.status.idle":"2022-04-23T04:38:28.377109Z","shell.execute_reply.started":"2022-04-23T04:38:28.305382Z","shell.execute_reply":"2022-04-23T04:38:28.376399Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"best_f_image_path, best_f_mask_path = valid_dataset[0][2:]\nbest_f_image_path, best_f_mask_path","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.378236Z","iopub.execute_input":"2022-04-23T04:38:28.378597Z","iopub.status.idle":"2022-04-23T04:38:28.390431Z","shell.execute_reply.started":"2022-04-23T04:38:28.378561Z","shell.execute_reply":"2022-04-23T04:38:28.389747Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Define U-Net model","metadata":{}},{"cell_type":"markdown","source":"## part of U-Net models","metadata":{}},{"cell_type":"code","source":"#pytorch official\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1,bias=False),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n        #self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        #self.conv = DoubleConv(in_channels, out_channels)\n        \n    def forward(self, x1,x2):\n        x1 = self.up(x1)\n        \n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX // 2, diffX - diffX //2,\n                        diffY // 2, diffY - diffY //2])\n        \n        x = torch.cat([x2,x1],dim=1)\n        return self.conv(x)\n    \nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.391608Z","iopub.execute_input":"2022-04-23T04:38:28.392036Z","iopub.status.idle":"2022-04-23T04:38:28.406892Z","shell.execute_reply.started":"2022-04-23T04:38:28.392000Z","shell.execute_reply":"2022-04-23T04:38:28.406286Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## main part of U-Net","metadata":{}},{"cell_type":"code","source":"#pytorch official\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes,bilinear=False):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64,128)\n        self.down2 = Down(128,256)\n        self.down3 = Down(256,512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512,1024 // factor)\n        self.up1 = Up(1024,512 // factor, bilinear)\n        self.up2 = Up(512,256 // factor, bilinear)\n        self.up3 = Up(256,128 // factor, bilinear)\n        self.up4 = Up(128,64, bilinear)\n        self.outc = OutConv(64,n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5,x4)\n        x = self.up2(x,x3)\n        x = self.up3(x,x2)\n        x = self.up4(x,x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.409104Z","iopub.execute_input":"2022-04-23T04:38:28.409983Z","iopub.status.idle":"2022-04-23T04:38:28.420829Z","shell.execute_reply.started":"2022-04-23T04:38:28.409946Z","shell.execute_reply":"2022-04-23T04:38:28.420021Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Custom metrics","metadata":{}},{"cell_type":"code","source":"def Dice_Coeff(x,y,flag):\n    DICE = []\n    #x:predmask, y:truemask\n    x = CFG.to_numpy(x)\n    y = CFG.to_numpy(y)\n    x1 = copy.copy(x)\n    y1 = copy.copy(y)\n    x2 = copy.copy(x)\n    y2 = copy.copy(y)\n    x3 = copy.copy(x)\n    y3 = copy.copy(y)\n    \n    if flag == 1:#foreground\n        x1[x1==0] = 3\n        y1[y1==0] = 3\n        x1[x1==1] = 0\n        y1[y1==1] = 0\n        x1[x1==2] = 0\n        y1[y1==2] = 0\n        x1[x1==3] = 1\n        y1[y1==3] = 1\n        x1 = torch.tensor(x1)\n        y1 = torch.tensor(y1)\n        \n        #Foreground = []\n        inter = x1&y1\n        for i in range(CFG.BATCH_SIZE):\n            intersection = torch.sum(inter[i])\n            dice = (2*intersection)/(torch.sum(x1[i])+torch.sum(y1[i]))                \n            DICE.append(dice)\n        \n    elif flag == 2:#background\n        x2[x2==1] = 1\n        y2[y2==1] = 1\n        x2[x2==2] = 0\n        y2[y2==2] = 0\n        x2[x2==0] = 0\n        y2[y2==0] = 0\n        x2 = torch.tensor(x2)\n        y2 = torch.tensor(y2)\n\n        #Background = []\n        inter = x2&y2\n        for i in range(CFG.BATCH_SIZE):\n            intersection = torch.sum(inter[i])\n            dice = (2*intersection)/(torch.sum(x2[i])+torch.sum(y2[i]))\n            DICE.append(dice)\n            \n    elif flag == 3:#border\n        x3[x3==1] = 0\n        y3[y3==1] = 0\n        x3[x3==2] = 1\n        y3[y3==2] = 1\n        x3[x3==0] = 0\n        y3[y3==0] = 0\n        x3 = torch.tensor(x3)\n        y3 = torch.tensor(y3)\n\n        #Border = []\n        inter = x3&y3\n        for i in range(CFG.BATCH_SIZE):\n            intersection = torch.sum(inter[i])\n            #dice = (2*intersection)/(CFG.IMAGE_SIZE*CFG.IMAGE_SIZE+CFG.IMAGE_SIZE*CFG.IMAGE_SIZE)\n            dice = (2*intersection)/(torch.sum(x3[i])+torch.sum(y3[i]))\n            DICE.append(dice)\n\n    return DICE","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.421989Z","iopub.execute_input":"2022-04-23T04:38:28.422511Z","iopub.status.idle":"2022-04-23T04:38:28.438457Z","shell.execute_reply.started":"2022-04-23T04:38:28.422475Z","shell.execute_reply":"2022-04-23T04:38:28.437744Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Visualize image (input and mask)","metadata":{}},{"cell_type":"code","source":"def show_pred_mask(original,true_tensor,out_tensor,cnt):\n        unnormalize = transforms.Normalize(\n        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n        std=[1/0.229, 1/0.224, 1/0.255]\n        )\n        original = unnormalize(original)\n\n        y = CFG.to_numpy(true_tensor)\n        z = CFG.to_numpy(out_tensor)\n\n        original = original.permute(2,1,0)\n        original = CFG.to_numpy(original)\n        original = np.rot90(original)\n        original = np.flipud(original)\n        \n        #convert [0,127,255] -> [0,1,2] #0が黒→物体内部、127がグレー→背景、255が白→物体輪郭\n        #mask_images[mask_images == 127] = 1\n        #mask_images[mask_images == 255] = 2\n\n        y[y==0] = 255\n        y[y==1] = 127\n        y[y==2] = 0\n\n        z[z==0] = 255\n        z[z==1] = 127\n        z[z==2] = 0\n\n        n_data = 3\n        row=1\n        col=3\n        \n        fig, ax = plt.subplots(nrows=row, ncols=col,figsize=(15,18))\n        #input image\n        ax[0].imshow(original)\n        #truth mask\n        ax[1].imshow(y,cmap='Greys')\n        #pred mask\n        ax[2].imshow(z,cmap='Greys')\n        plt.show()\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.441683Z","iopub.execute_input":"2022-04-23T04:38:28.441891Z","iopub.status.idle":"2022-04-23T04:38:28.452198Z","shell.execute_reply.started":"2022-04-23T04:38:28.441844Z","shell.execute_reply":"2022-04-23T04:38:28.451315Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Save best,median,worst tensor\n* original tensor\n* pred tensor\n* true tensor","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import statistics\nplot_train_loss = []\nplot_train_dice1 = []\nplot_train_dice2 = []\nplot_train_dice3 = []\n\nplot_valid_loss = []\nplot_valid_dice1 = []\nplot_valid_dice2 = []\nplot_valid_dice3 = []\n\nL_t = []\nD1_t = []\nL_v = []\nD1_v = []\n\nD2_t = []\nD2_v = []\n\nD3_t = []\nD3_v = []\n\n\n\ndef training_model(model, datasets, dataloaders, criterion, optimizer, num_epochs, device):\n    best_loss = 2.0\n    best_f_dice = 0.0\n    worst_loss = 0.0\n    \n    worst_f_dice = 1.0\n    median_loss = 0.0\n    median_f_dice = 0.0\n    \n    best_b_dice = 0.0\n    worst_b_dice = 1.0\n    median_b_dice = 0.0\n    \n    best_n_dice = 0.0\n    worst_n_dice = 1.0\n    median_n_dice = 0.0\n    #scaler = GradScaler()\n    \n    max_value = 0\n    min_value = 10**9\n    med_value = 0\n    \n    medlist = []\n    med_ori = []\n    med_pre = []\n    med_tru = []\n    \n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print('-'*10)\n        \n        for phase in ['train','valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_loss = 0.0\n            running_dice1 = 0.0\n            running_dice2 = 0.0\n            running_dice3 = 0.0\n                \n            stream = tqdm(dataloaders[phase])\n            for cnt, (inputs, masks,im_path,ms_path) in enumerate(stream, start=1):\n                total_value = []\n\n                original = inputs\n                inputs = inputs.to(device=CFG.DEVICE, dtype=torch.float32)\n                masks = masks.to(device=CFG.DEVICE, dtype=torch.long)\n                optimizer.zero_grad()\n                \n                #with autocast():\n                with torch.set_grad_enabled(phase=='train'):\n                    model = model.to(CFG.DEVICE)\n                    outputs = model(inputs)\n                    \n                    pred_masks = F.softmax(outputs, dim=1).float()\n                    masks =  masks.squeeze(1)\n                    loss = criterion(pred_masks, masks)#CrossEntropyLoss\n                    _,ch = torch.max(outputs, -3)\n\n                    flag = 1\n                    dice11 = sum(Dice_Coeff(ch,masks, flag))/CFG.BATCH_SIZE#return array(dice1,dice2,...,dice(batch_size))\n                    dice22 = sum(Dice_Coeff(ch,masks, flag+1))/CFG.BATCH_SIZE\n                    dice33 = sum(Dice_Coeff(ch,masks, flag+2))/CFG.BATCH_SIZE\n                    dice1 = Dice_Coeff(ch, masks,flag)\n                    dice2 = Dice_Coeff(ch, masks,flag+1)\n                    dice3 = Dice_Coeff(ch, masks, flag+2)\n                    #dice11 = sum(dice1)/CFG.BATCH_SIZE#return array(dice1,dice2,...,dice(batch_size))\n                    #dice22 = sum(dice2)/CFG.BATCH_SIZE\n                    #dice33 = sum(dice3)/CFG.BATCH_SIZE\n                    for i in range(CFG.BATCH_SIZE):\n                        total_value.append((dice1[i]+dice2[i]+dice3[i]).item())\n\n                    #max dice\n                    sum_max = max(total_value)\n                    if sum_max > max_value:\n                        max_value = sum_max\n                        max_idx = total_value.index(max_value)\n                        max_ori = original[max_idx]\n                        max_pre = masks[max_idx]\n                        max_tru = ch[max_idx]\n                    \n                    #min dice\n                    sum_min = min(total_value)\n                    if sum_min < min_value:\n                        min_value = sum_min\n                        min_idx = total_value.index(min_value)\n                        min_ori = original[min_idx]\n                        min_pre = masks[min_idx]\n                        min_tru = ch[min_idx]\n                        \n                    #med dice\n                    total_value.append(0)\n                    sum_med = statistics.median(total_value)\n                    if sum_med > med_value:\n                        med_value = sum_med\n                        med_idx = total_value.index(med_value)\n                        med_ori = original[med_idx]\n                        med_pre = masks[med_idx]\n                        med_tru = ch[med_idx]\n                        \n                    #Diceの真ん中の値を取得したい\n                    #今浮かんでる構成は、各バッチごとの中央を以下のコードで求めてそれぞれの値（idx,ori,pre,tru）を配列で管理する。\n                    \n                    #med dice メモリ食いすぎる\n                    #total_value.sort()\n                    #sum_med = total_value[CFG.BATCH_SIZE//2]\n                    #medlist.append(sum_med)\n                    #med_idx = total_value.index(sum_med)\n                    #med_ori.append(original[med_idx])\n                    #med_pre.append(masks[med_idx])\n                    #med_tru.append(ch[med_idx])\n\n                    #dice11 = sum(Dice_Coeff(ch, masks,flag))/CFG.BATCH_SIZE#return array(dice1,dice2,...,dice(batch_size))\n                    #dice22 = sum(Dice_Coeff(ch, masks,flag+1))/CFG.BATCH_SIZE\n                    #dice33 = sum(Dice_Coeff(ch, masks, flag+2))/CFG.BATCH_SIZE\n                    running_loss += loss.item()\n                    running_dice1 += dice11\n                    running_dice2 += dice22\n                    running_dice3 += dice33\n                    \n                    if phase =='train':\n                        L_t.append(loss.item())\n                        D1_t.append(CFG.to_numpy(dice11))\n                        D2_t.append(CFG.to_numpy(dice22))\n                        D3_t.append(CFG.to_numpy(dice33))\n                    else:\n                        L_v.append(loss.item())\n                        D1_v.append(CFG.to_numpy(dice11))\n                        D2_v.append(CFG.to_numpy(dice22))\n                        D3_v.append(CFG.to_numpy(dice33))\n\n                    if cnt-1 == 0:\n                        show_pred_mask(original[0],masks[0],ch[0],cnt)\n                        show_pred_mask(original[1],masks[1],ch[1],cnt)\n                    else:\n                        continue\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n################################################################\n                    if phase == 'valid' and loss < best_loss:\n                        best_loss = loss\n                    if phase == 'valid' and loss > worst_loss:\n                        worst_loss = loss\n################################################################fffff\n                    if phase == 'valid' and dice11 > best_f_dice:\n                        best_f_dice = dice11\n                        print(f'[Foreground] Best Dice Result at the moment EPOCH:{epoch+1} Dice:{best_f_dice}')\n\n                    if phase == 'valid' and dice11 < worst_f_dice:\n                        worst_f_dice = dice11\n                        print(f'[Foreground] Worst Dice Result at the moment EPOCH:{epoch+1} Dice:{worst_f_dice}')\n\n################################################################bbbbb\n                    if phase == 'valid' and dice22 > best_b_dice:\n                        best_b_dice = dice22\n                        print(f'[Background] Best Dice Result at the moment EPOCH:{epoch+1} Dice:{best_b_dice}')\n\n                    if phase == 'valid' and dice22 < worst_b_dice:\n                        worst_b_dice = dice22\n                        print(f'[Background] Worst Dice Result at the moment EPOCH:{epoch+1} Dice:{worst_b_dice}')\n                        \n################################################################bbbbb\n                    if phase == 'valid' and dice33 > best_n_dice:\n                        best_n_dice = dice33\n                        print(f'[Border] Best Border Dice Result at the moment EPOCH:{epoch+1} Dice:{best_n_dice}')\n\n                    if phase == 'valid' and dice33 <worst_n_dice:\n                        worst_n_dice = dice33\n                        print(f'[Border] Worst Border Dice Result at the moment EPOCH:{epoch+1} Dice:{worst_n_dice}')\n\n            epoch_loss = running_loss/len(dataloaders[phase])\n            epoch_dice1 = running_dice1/len(dataloaders[phase])\n            epoch_dice2 = running_dice2/len(dataloaders[phase])\n            epoch_dice3 = running_dice3/len(dataloaders[phase])\n            \n            if phase == 'train':\n                plot_train_loss.append(epoch_loss)\n                plot_train_dice1.append(epoch_dice1)\n                plot_train_dice2.append(epoch_dice2)\n                plot_train_dice3.append(epoch_dice3)\n            else:\n                plot_valid_loss.append(epoch_loss)\n                plot_valid_dice1.append(epoch_dice1)\n                plot_valid_dice2.append(epoch_dice2)\n                plot_valid_dice3.append(epoch_dice3)\n            \n            print(f'{phase} Loss: {epoch_loss} Foreground Dice: {epoch_dice1} Background Dice: {epoch_dice2} Border Dice: {epoch_dice3}')\n            \n        print()\n        \n    #max dice image\n    print(f'max dice image')\n    show_pred_mask(max_ori,max_pre,max_tru,cnt)\n    \n    #median dice image\n    #medlist.append(0)\n    #medice = statistics.median(medlist)\n    #med_idx = medlist.index(medice)\n    print(f'median dice image')\n    show_pred_mask(med_ori,med_pre,med_tru,cnt)\n    \n    #min dice image\n    print(f'min dice image')\n    show_pred_mask(min_ori,min_pre,min_tru,cnt)\n    \n    print(f'Best val Loss:{best_loss}')\n    print(f'Median val Loss:{(best_loss+worst_loss)/2}')\n    print(f'Worst val Loss:{worst_loss}')\n        \n    print(f'[Foreground] Best val Dice:{best_f_dice}　')\n    print(f'[Foreground] Median val Dice:{(best_f_dice+worst_f_dice)/2}　')\n    print(f'[Foreground] Worst val Dice:{worst_f_dice}　')\n    \n    print(f'[Background] Best val Dice:{best_b_dice}　')\n    print(f'[Background] Median val Dice:{(best_b_dice+worst_b_dice)/2}　')\n    print(f'[Background] Worst val Dice:{worst_b_dice}　')\n    \n    print(f'[Border] Best val Dice:{best_n_dice}　')\n    print(f'[Border] Median val Dice:{(best_n_dice+worst_n_dice)/2}　')\n    print(f'[Border] Worst val Dice:{worst_n_dice}　')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.453769Z","iopub.execute_input":"2022-04-23T04:38:28.454219Z","iopub.status.idle":"2022-04-23T04:38:28.493615Z","shell.execute_reply.started":"2022-04-23T04:38:28.454184Z","shell.execute_reply":"2022-04-23T04:38:28.492923Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"datasets = {'train': train_dataset,\n            'valid': valid_dataset}\n\ndataloaders = {'train': train_loader,\n               'valid': valid_loader}\nmodel = UNet(n_channels=3, n_classes=3)\n#optimizer = optim.SGD(model.paradfmeters(),lr=0.001,momentum=0.9)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\nnum_epochs = 30","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.498308Z","iopub.execute_input":"2022-04-23T04:38:28.498645Z","iopub.status.idle":"2022-04-23T04:38:28.767164Z","shell.execute_reply.started":"2022-04-23T04:38:28.498618Z","shell.execute_reply":"2022-04-23T04:38:28.766407Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"trained_model = training_model(model,datasets, dataloaders, criterion, optimizer, num_epochs, CFG.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T04:38:28.768225Z","iopub.execute_input":"2022-04-23T04:38:28.770043Z","iopub.status.idle":"2022-04-23T05:23:15.730894Z","shell.execute_reply.started":"2022-04-23T04:38:28.770002Z","shell.execute_reply":"2022-04-23T05:23:15.729907Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"data = (list(np.array(D1_v)),list(np.array(D2_v)),list(np.array(D3_v)))\nfig,ax = plt.subplots()\nax.set_title('Dice')\nax.set_xticklabels(['Foreground', 'Background', 'Border'])\nax.boxplot(data)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:15.732518Z","iopub.execute_input":"2022-04-23T05:23:15.732900Z","iopub.status.idle":"2022-04-23T05:23:15.915084Z","shell.execute_reply.started":"2022-04-23T05:23:15.732829Z","shell.execute_reply":"2022-04-23T05:23:15.914382Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"data = (list(np.array(D1_t)),list(np.array(D2_t)),list(np.array(D3_t)))\nfig,ax = plt.subplots()\nax.set_title('Dice')\nax.set_xticklabels(['Foreground', 'Background', 'Border'])\nax.boxplot(data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:31:02.178821Z","iopub.execute_input":"2022-04-23T05:31:02.179086Z","iopub.status.idle":"2022-04-23T05:31:02.372704Z","shell.execute_reply.started":"2022-04-23T05:31:02.179056Z","shell.execute_reply":"2022-04-23T05:31:02.371972Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss\nplt.title(\"Loss\",fontsize=18)\nplt.xlabel(\"Epoch\",fontsize=14)\nplt.ylabel(\"Loss\",fontsize=14)\n\nplt.ylim(0.8, 1.1)\nplt.xlim(0, num_epochs+1, 1)\n\nplt.xticks(np.arange(0, num_epochs+1, 1))\nplt.plot(range(1, num_epochs+1),plot_train_loss,label='Training Loss',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_loss,label='Validation Loss',marker ='o')\nplt.legend(frameon=False, fontsize=14)\n\nplt.show()\n\n#dice1\nplt.title(\"Dice Foreground\",fontsize=18)\nplt.xlabel(\"Epoch\",fontsize=14)\nplt.ylabel(\"Dice\",fontsize=14)\n\nplt.ylim(0.1, 0.83)\nplt.xlim(0, num_epochs+1, 1)\n\nplt.xticks(np.arange(0, num_epochs+1, 1))\n#plt.plot(range(1, num_epochs+1),plot_train_dice1,label='Training Dice',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_dice1,label='Foreground Dice',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_dice2,label='Background Dice',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_dice3,label='border Dice',marker ='o')\nplt.legend(frameon=False, fontsize=14)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:43:57.269316Z","iopub.execute_input":"2022-04-23T05:43:57.269574Z","iopub.status.idle":"2022-04-23T05:43:57.816344Z","shell.execute_reply.started":"2022-04-23T05:43:57.269546Z","shell.execute_reply":"2022-04-23T05:43:57.815683Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(L_v, num_epochs)))\nplt.title('Loss')\nplt.ylabel('loss')\nplt.ylim([0.7, 1.2])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:16.644273Z","iopub.execute_input":"2022-04-23T05:23:16.644518Z","iopub.status.idle":"2022-04-23T05:23:17.161416Z","shell.execute_reply.started":"2022-04-23T05:23:16.644484Z","shell.execute_reply":"2022-04-23T05:23:17.160772Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(D1_v, num_epochs)))\nplt.title('Dice Foreground')\nplt.ylabel('dice')\nplt.ylim([0, 1.0])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:17.162571Z","iopub.execute_input":"2022-04-23T05:23:17.162833Z","iopub.status.idle":"2022-04-23T05:23:17.965507Z","shell.execute_reply.started":"2022-04-23T05:23:17.162793Z","shell.execute_reply":"2022-04-23T05:23:17.964807Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(D2_v, num_epochs)))\nplt.title('Dice Background')\nplt.ylabel('dice')\nplt.ylim([0, 1.0])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:17.966645Z","iopub.execute_input":"2022-04-23T05:23:17.966941Z","iopub.status.idle":"2022-04-23T05:23:18.633278Z","shell.execute_reply.started":"2022-04-23T05:23:17.966905Z","shell.execute_reply":"2022-04-23T05:23:18.632625Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(D3_v, num_epochs)))\nplt.title('Dice Border')\nplt.ylabel('dice')\nplt.ylim([0, 1.0])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:18.636965Z","iopub.execute_input":"2022-04-23T05:23:18.640007Z","iopub.status.idle":"2022-04-23T05:23:19.194609Z","shell.execute_reply.started":"2022-04-23T05:23:18.639967Z","shell.execute_reply":"2022-04-23T05:23:19.193925Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# d = (2*intersection)/(CFG.IMAGE_SIZE*CFG.IMAGE_SIZE*CFG.BATCH_SIZE + CFG.IMAGE_SIZE*CFG.IMAGE_SIZE*CFG.BATCH_SIZE)","metadata":{}},{"cell_type":"code","source":"import torch\ntensorx = torch.tensor([[[1,0,1,1],[1,1,1,1],[1,0,0,1],[1,1,0,0]],[[1,0,1,0],[0,0,1,1],[0,0,0,1],[0,1,0,0]]])\ntensory = torch.tensor([[[1,0,0,1],[1,0,0,1],[1,1,0,1],[1,0,0,0]],[[0,1,0,1],[0,1,0,1],[0,1,1,1],[1,0,0,0]]])\n\nprint(f'pred {tensorx}')\nprint(f'true {tensory}')\nprint('------------------')\nprint(f'and {tensorx & tensory}')\nprint('------------------')\nprint(tensorx[0])\n\nprint(torch.sum(tensorx[0]))\n\nprint(torch.sum(tensorx[i])+sum(tensory[i]))\n\nd = []\ninter = tensorx&tensory\nprint(f'intersection {inter}')\n\nfor i in range(2):\n    intersection = torch.sum(inter[i])\n    print(intersection)\n    dice = (2*intersection)/(torch.sum(tensorx[i])+torch.sum(tensory[i]))\n    d.append(dice)\nprint(f'Dice{d}')","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:19.195678Z","iopub.execute_input":"2022-04-23T05:23:19.195935Z","iopub.status.idle":"2022-04-23T05:23:19.591233Z","shell.execute_reply.started":"2022-04-23T05:23:19.195900Z","shell.execute_reply":"2022-04-23T05:23:19.590047Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"import torch\n\nori=[]\npre=[]\nch=[]\n\ntensorx = torch.tensor([[[1,0,1,1],[1,1,1,1],[1,0,0,1],[1,1,0,0]],[[1,0,1,0],[0,0,1,1],[0,0,0,1],[0,1,0,0]]])\ntensory = torch.tensor([[[1,0,0,1],[1,0,0,1],[1,1,0,1],[1,0,0,0]],[[0,1,0,1],[0,1,0,1],[0,1,1,1],[1,0,0,0]]])\n\nori.append(tensorx)\nprint(ori)\nori.append(tensory)\nprint(ori)\n\nprint(ori[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:19.592528Z","iopub.status.idle":"2022-04-23T05:23:19.592956Z","shell.execute_reply.started":"2022-04-23T05:23:19.592720Z","shell.execute_reply":"2022-04-23T05:23:19.592742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = [1,4,2,5]\nl","metadata":{"execution":{"iopub.status.busy":"2022-04-23T05:23:19.594605Z","iopub.status.idle":"2022-04-23T05:23:19.595023Z","shell.execute_reply.started":"2022-04-23T05:23:19.594789Z","shell.execute_reply":"2022-04-23T05:23:19.594812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}