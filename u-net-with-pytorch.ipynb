{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport copy\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import Adam\n\n\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\n#import torchvision.transforms.functional as F\n#from torchvision.datasets import OxfordIIITPet\n\nfrom PIL import Image\nimport io\nfrom io import BytesIO \n\nimport cv2\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout,GridDropout\n    )\n\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import Image as Im\nfrom PIL import ImageOps\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"2hbZj8CKoAc-","execution":{"iopub.status.busy":"2022-04-08T00:40:13.367798Z","iopub.execute_input":"2022-04-08T00:40:13.368128Z","iopub.status.idle":"2022-04-08T00:40:22.071997Z","shell.execute_reply.started":"2022-04-08T00:40:13.368029Z","shell.execute_reply":"2022-04-08T00:40:22.071252Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":" class CFG:\n        BASE_PATH = '../input/oxfordiiitpet-dataset/'\n        IMAGE_PATH = '../input/oxfordiiitpet-dataset/images/images/'\n        ANNOTATION_PATH = '../input/oxfordiiitpet-dataset/annotations/annotations/'\n        \n        DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        IMAGE_SIZE = 256\n        BATCH_SIZE = 16\n        \n        DEBUG  = False\n        def debug(DEBUG):\n            if DEBUG:\n                df = df.sample(frac = 0.5).reset_index(drop = True)\n            return df\n        \n        def to_numpy(tensor):\n            return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.074343Z","iopub.execute_input":"2022-04-08T00:40:22.074729Z","iopub.status.idle":"2022-04-08T00:40:22.089813Z","shell.execute_reply.started":"2022-04-08T00:40:22.074694Z","shell.execute_reply":"2022-04-08T00:40:22.089235Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Create DataFrame","metadata":{}},{"cell_type":"code","source":"all_df = pd.read_table(CFG.ANNOTATION_PATH+'list.txt',sep=' ',skiprows=5 )\nall_df = all_df.iloc[:,:4]\nall_df = all_df.set_axis(['image_name','id','species','breed'],axis=1)\nall_df","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.093761Z","iopub.execute_input":"2022-04-08T00:40:22.094437Z","iopub.status.idle":"2022-04-08T00:40:22.151156Z","shell.execute_reply.started":"2022-04-08T00:40:22.094334Z","shell.execute_reply":"2022-04-08T00:40:22.150503Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Split train and validation 8:2","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(all_df, test_size = 0.2)\nprint(train_df.shape, valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.153124Z","iopub.execute_input":"2022-04-08T00:40:22.153557Z","iopub.status.idle":"2022-04-08T00:40:22.161560Z","shell.execute_reply.started":"2022-04-08T00:40:22.153522Z","shell.execute_reply":"2022-04-08T00:40:22.160848Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.162580Z","iopub.execute_input":"2022-04-08T00:40:22.164028Z","iopub.status.idle":"2022-04-08T00:40:22.176222Z","shell.execute_reply.started":"2022-04-08T00:40:22.163993Z","shell.execute_reply":"2022-04-08T00:40:22.175519Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"valid_df = valid_df.reset_index(drop=True)\nvalid_df","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.177405Z","iopub.execute_input":"2022-04-08T00:40:22.178096Z","iopub.status.idle":"2022-04-08T00:40:22.193838Z","shell.execute_reply.started":"2022-04-08T00:40:22.178050Z","shell.execute_reply":"2022-04-08T00:40:22.193186Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Visualize images","metadata":{}},{"cell_type":"code","source":"#nomal images\nimage = Im.open(CFG.IMAGE_PATH+all_df[\"image_name\"][0]+\".jpg\")\n#image = Im.open('../input/oxfordiiitpet-dataset/images/images/Abyssinian_10.jpg')\ndisplay(image)\ni = np.array(image)\ni.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.194861Z","iopub.execute_input":"2022-04-08T00:40:22.195570Z","iopub.status.idle":"2022-04-08T00:40:22.305194Z","shell.execute_reply.started":"2022-04-08T00:40:22.195535Z","shell.execute_reply":"2022-04-08T00:40:22.304590Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#mask image\n#mask_image = PIL.ImageOps.autocontrast(load_img('../input/oxfordiiitpet-dataset/annotations/annotations/trimaps/Abyssinian_10.png'))\nmask_image = PIL.ImageOps.autocontrast(load_img(CFG.ANNOTATION_PATH+'trimaps/'+all_df[\"image_name\"][0]+'.png'))\ndisplay(mask_image)\nrgb2gry = transforms.Grayscale()\nmask_images = mask_image.convert('L')\n#mask_image = mask_image.transpose(1,0,2)\nmask = np.array(mask_image)\n#print(mask)\n#mask = mask.transpose(1,0,2)\n\nobj_ids = np.unique(mask)\nprint(obj_ids)\n\n#new = np.where((mask!=0)&(mask!=255), 1,mask)\n#new = np.where((new!=0)&(new!=127), 2,new)\n# convert [0,127,255] to [0,1,2]\nmask[mask == 0] = 1\nmask[mask == 127] = 0\nmask[mask == 255] = 1\n#print(mask)\nprint(np.unique(mask))\n#obj_ids[:]\n#masks = mask == obj_ids[:,None,None]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.306096Z","iopub.execute_input":"2022-04-08T00:40:22.306770Z","iopub.status.idle":"2022-04-08T00:40:22.355059Z","shell.execute_reply.started":"2022-04-08T00:40:22.306737Z","shell.execute_reply":"2022-04-08T00:40:22.354381Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(type(image))\nprint(type(mask_image))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.356180Z","iopub.execute_input":"2022-04-08T00:40:22.356564Z","iopub.status.idle":"2022-04-08T00:40:22.361738Z","shell.execute_reply.started":"2022-04-08T00:40:22.356530Z","shell.execute_reply":"2022-04-08T00:40:22.360999Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# image and mask","metadata":{}},{"cell_type":"code","source":"def get_concat_h(im1, im2):\n    dst = Im.new('RGB', (im1.width + im2.width, im1.height))\n    dst.paste(im1, (0, 0))\n    dst.paste(im2, (im1.width, 0))\n    return dst\n\nget_concat_h(image, mask_image)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.364886Z","iopub.execute_input":"2022-04-08T00:40:22.365579Z","iopub.status.idle":"2022-04-08T00:40:22.446162Z","shell.execute_reply.started":"2022-04-08T00:40:22.365546Z","shell.execute_reply":"2022-04-08T00:40:22.445520Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation function","metadata":{}},{"cell_type":"code","source":"def get_transform(data):\n    if data == 'train':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.HorizontalFlip(p=0.5),\n                A.GridDropout(ratio=0.2, unit_size_min=None, unit_size_max=None, holes_number_x=5, holes_number_y=5, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5),\n                A.Normalize(),\n                ToTensorV2()\n            ])\n    elif data == 'valid':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.Normalize(),\n                ToTensorV2()\n            ])","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.447536Z","iopub.execute_input":"2022-04-08T00:40:22.447993Z","iopub.status.idle":"2022-04-08T00:40:22.455962Z","shell.execute_reply.started":"2022-04-08T00:40:22.447956Z","shell.execute_reply":"2022-04-08T00:40:22.454904Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"len(all_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.457482Z","iopub.execute_input":"2022-04-08T00:40:22.457872Z","iopub.status.idle":"2022-04-08T00:40:22.467388Z","shell.execute_reply.started":"2022-04-08T00:40:22.457842Z","shell.execute_reply":"2022-04-08T00:40:22.466583Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#confirm path for dataset class\nimage_path = CFG.IMAGE_PATH\nmask_path = CFG.ANNOTATION_PATH\nprint(os.path.join(image_path, all_df[\"image_name\"][0]+'.jpg'))\nprint(os.path.join(mask_path, 'trimaps/'+all_df[\"image_name\"][0]+'.png'))","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.468952Z","iopub.execute_input":"2022-04-08T00:40:22.469604Z","iopub.status.idle":"2022-04-08T00:40:22.476800Z","shell.execute_reply.started":"2022-04-08T00:40:22.469548Z","shell.execute_reply":"2022-04-08T00:40:22.475850Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, df, transforms=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.df = df\n        self.image_names = df[\"image_name\"]\n        self.transforms = transforms\n        \n    def __len__(self):\n        #print(len(self.df))\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        # get path\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.image_paths, image_name+'.jpg')\n        mask_path = os.path.join(self.mask_paths, 'trimaps/'+image_name+'.png')\n        #print(image_path,mask_path)\n        #open image\n        image = Im.open(image_path)\n        mask_images = PIL.ImageOps.autocontrast(load_img(mask_path))\n        rgb2gry = transforms.Grayscale()\n        mask_images = rgb2gry(mask_images)\n        #PIL to numpy\n        image = np.array(image)\n        image = image[:,:,:3]#remove some of alpha channels\n        mask_images = np.array(mask_images)\n        #convert [0,127,255] -> [0,1,2]\n        mask_images[mask_images == 127] = 1\n        mask_images[mask_images == 255] = 2\n\n        obj_ids = np.unique(mask_images)\n        #print(obj_ids)\n        \n        if self.transforms:\n            augmented = self.transforms(image=image,mask=mask_images)\n            image,mask = augmented['image'],augmented['mask']\n        #print(image.shape, mask.shape)\n        mask  = mask.unsqueeze(0)\n        #mask = mask.permute(2,1,0)\n        #mask = np.expand_dims(mask, axis=0)\n\n        return image,mask","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.478486Z","iopub.execute_input":"2022-04-08T00:40:22.479028Z","iopub.status.idle":"2022-04-08T00:40:22.489446Z","shell.execute_reply.started":"2022-04-08T00:40:22.478993Z","shell.execute_reply":"2022-04-08T00:40:22.488742Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    train_df,\n    transforms = get_transform(data='train'),\n)\nvalid_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    valid_df,\n    transforms = get_transform(data='valid'),\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.490825Z","iopub.execute_input":"2022-04-08T00:40:22.491300Z","iopub.status.idle":"2022-04-08T00:40:22.500548Z","shell.execute_reply.started":"2022-04-08T00:40:22.491266Z","shell.execute_reply":"2022-04-08T00:40:22.499807Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# CPUのコア数を確認\nimport os\nos.cpu_count()  # コア数","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.501582Z","iopub.execute_input":"2022-04-08T00:40:22.502174Z","iopub.status.idle":"2022-04-08T00:40:22.510333Z","shell.execute_reply.started":"2022-04-08T00:40:22.502137Z","shell.execute_reply":"2022-04-08T00:40:22.509559Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True)\ntrain_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.511867Z","iopub.execute_input":"2022-04-08T00:40:22.513573Z","iopub.status.idle":"2022-04-08T00:40:22.640140Z","shell.execute_reply.started":"2022-04-08T00:40:22.513531Z","shell.execute_reply":"2022-04-08T00:40:22.639421Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"valid_loader = DataLoader(valid_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True)\nvalid_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.641349Z","iopub.execute_input":"2022-04-08T00:40:22.641849Z","iopub.status.idle":"2022-04-08T00:40:22.679095Z","shell.execute_reply.started":"2022-04-08T00:40:22.641810Z","shell.execute_reply":"2022-04-08T00:40:22.678459Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Define U-Net model","metadata":{}},{"cell_type":"markdown","source":"## part of U-Net models","metadata":{}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, stride=1, padding=1,bias=False),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        self.conv = DoubleConv(in_channels, out_channels)\n        \n    def forward(self, x1,x2):\n        x1 = self.up(x1)\n        \n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX // 2, diffX - diffX //2,\n                        diffY // 2, diffY - diffY //2])\n        \n        x = torch.cat([x2,x1],dim=1)\n        return self.conv(x)\n    \nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.680306Z","iopub.execute_input":"2022-04-08T00:40:22.680851Z","iopub.status.idle":"2022-04-08T00:40:22.695266Z","shell.execute_reply.started":"2022-04-08T00:40:22.680810Z","shell.execute_reply":"2022-04-08T00:40:22.694519Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## main part of U-Net","metadata":{}},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self, n_channels, n_classes):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64,128)\n        self.down2 = Down(128,256)\n        self.down3 = Down(256,512)\n        self.down4 = Down(512,1024)\n        self.up1 = Up(1024,512)\n        self.up2 = Up(512,256)\n        self.up3 = Up(256,128)\n        self.up4 = Up(128,64)\n        self.outc = OutConv(64,n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5,x4)\n        x = self.up2(x,x3)\n        x = self.up3(x,x2)\n        x = self.up4(x,x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.697683Z","iopub.execute_input":"2022-04-08T00:40:22.698145Z","iopub.status.idle":"2022-04-08T00:40:22.707814Z","shell.execute_reply.started":"2022-04-08T00:40:22.698084Z","shell.execute_reply":"2022-04-08T00:40:22.707113Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Custom metrics","metadata":{}},{"cell_type":"code","source":"def Dice_Coeff(x,y):\n    #print(x.shape, y.shape)\n    x = x.flatten()\n    y = y.flatten()\n    #ans = x&y\n    #print(len(x&y)print()\n    \n    intersection = sum(x*y)\n    #print(intersection)\n    dice = (2*intersection+1.0)/(sum(x) + sum(y)+1.0)\n    #print(intersection)\n    return dice","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.710351Z","iopub.execute_input":"2022-04-08T00:40:22.711179Z","iopub.status.idle":"2022-04-08T00:40:22.719751Z","shell.execute_reply.started":"2022-04-08T00:40:22.711144Z","shell.execute_reply":"2022-04-08T00:40:22.719033Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Visualize image (input and mask)","metadata":{}},{"cell_type":"code","source":"def show_pred_mask(original,true_tensor,out_tensor,cnt):\n    #fig = plt.figure(figsize=(16, 12))\n    #x = CFG.to_numpy(in_tensor).transpose(1, 2, 0)\n    \n    unnormalize = transforms.Normalize(\n    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n    std=[1/0.229, 1/0.224, 1/0.255]\n    )\n    original = unnormalize(original)\n    \n    y = CFG.to_numpy(true_tensor)\n    z = CFG.to_numpy(out_tensor)\n    #print(y,z)\n    original = original.permute(2,1,0)\n    original = CFG.to_numpy(original)\n    original = np.rot90(original)\n    original = np.flipud(original)\n    #print(original.shape)\n    \n    y[y==0] = 255\n    y[y==1] = 127\n    y[y==2] = 0\n    \n    z[z==0] = 255\n    z[z==1] = 127\n    z[z==2] = 0\n    #print(y,z)\n    n_data = 3 # 表示するデータ数\n    row=1 # 行数\n    col=3 # 列数\n    fig, ax = plt.subplots(nrows=row, ncols=col,figsize=(15,18))\n    #fig = plt.figure()\n\n    #input image\n    ax[0].imshow(original)\n    \n    #truth mask\n    ax[1].imshow(y,cmap='Greys')\n    \n    #pred mask\n    ax[2].imshow(z,cmap='Greys')\n    \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.722093Z","iopub.execute_input":"2022-04-08T00:40:22.722501Z","iopub.status.idle":"2022-04-08T00:40:22.732296Z","shell.execute_reply.started":"2022-04-08T00:40:22.722474Z","shell.execute_reply":"2022-04-08T00:40:22.731606Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"plot_train_loss = []\nplot_train_dice = []\n\nplot_valid_loss = []\nplot_valid_dice = []\n\ndef training_model(model, datasets, dataloaders, criterion, optimizer, num_epochs, device):\n    best_model_weights = copy.deepcopy(model.state_dict())\n    best_dice = 0.0\n    \n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print('-'*10)\n        \n        for phase in ['train','valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_loss = 0.0\n            running_dice = 0.0\n            \n            stream = tqdm(dataloaders[phase])\n            for cnt, (inputs, masks) in enumerate(stream, start=1):\n            #for inputs, masks in stream:\n                #print(f'inputs and masks shape {inputs.shape}, {masks.shape}')\n                original = inputs\n                inputs = inputs.to(device=CFG.DEVICE, dtype=torch.float32)\n                masks = masks.to(device=CFG.DEVICE, dtype=torch.long)\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase=='train'):\n                    model = model.to(CFG.DEVICE)\n                    outputs = model(inputs)\n                    \n                    pred_masks = F.softmax(outputs, dim=1).float()\n                    masks =  masks.squeeze(1)\n                    #_,pred_masks = torch.max(outputs, -3)\n                    loss = criterion(pred_masks, masks)#CrossEntropyLoss\n                    _,ch = torch.max(outputs, -3)\n                    #print(cnt)\n                    #入力と対応する予測マスクを表示するための関数を作る\n                    if cnt-1 == 0:\n                        show_pred_mask(original[0],masks[0],ch[0],cnt)\n                    else:\n                        continue\n                    \n                    #dice = Dice_Coeff(_, masks)\n                    #print(ch,masks)\n                    #print(loss)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                    running_loss += loss.item()\n\n                    #running_acc += accuracy_score(CFG.to_numpy(pred_masks),CFG.to_numpy(masks))\n                    #running_dice += Dice_Coeff(CFG.to_numpy(_),CFG.to_numpy(masks))\n                    #print(running_dice)\n                    \n            epoch_loss = running_loss / cnt\n            #epoch_acc = running_acc / batch\n            #epoch_dice = running_dice / batch\n            \n            if phase == 'train':\n                plot_train_loss.append(epoch_loss)\n                #plot_train_dice.append(running_dice/len(dataloaders[phase]))\n                #plot_train_loss.append(epoch_loss)\n                #plot_train_dice.append(epoch_dice)\n            else:\n                plot_valid_loss.append(running_loss/len(dataloaders[phase]))\n                #plot_valid_dice.append(running_dice/len(dataloaders[phase]))\n            \n            print(f'{phase} Loss: {epoch_loss}')# Dice: {running_dice/len(dataloaders[phase])}')\n            \n            #if phase == 'valid' and epoch_dice > best_dice:\n                #best_dice = epoch_dice\n                #best_model_weights = copy().deepcopy(model.state_dict())\n                \n        print()\n        \n    #print(f'Best val Dice:{best_dice}')\n          \n    #model.load_state_dict(best_model_weights)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.733705Z","iopub.execute_input":"2022-04-08T00:40:22.734147Z","iopub.status.idle":"2022-04-08T00:40:22.749722Z","shell.execute_reply.started":"2022-04-08T00:40:22.734113Z","shell.execute_reply":"2022-04-08T00:40:22.749001Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"datasets = {'train': train_dataset,\n            'valid': valid_dataset}\n\ndataloaders = {'train': train_loader,\n               'valid': valid_loader}\nmodel = UNet(n_channels=3, n_classes=3)\n#optimizer = optim.SGD(model.parameters(),lr=0.001,momentum=0.9)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\ncriterion = nn.CrossEntropyLoss()\n#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\nnum_epochs = 10","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:22.752118Z","iopub.execute_input":"2022-04-08T00:40:22.752364Z","iopub.status.idle":"2022-04-08T00:40:23.028329Z","shell.execute_reply.started":"2022-04-08T00:40:22.752332Z","shell.execute_reply":"2022-04-08T00:40:23.027631Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trained_model = training_model(model,datasets, dataloaders, criterion, optimizer, num_epochs, CFG.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:40:23.029612Z","iopub.execute_input":"2022-04-08T00:40:23.029844Z","iopub.status.idle":"2022-04-08T00:47:15.555822Z","shell.execute_reply.started":"2022-04-08T00:40:23.029812Z","shell.execute_reply":"2022-04-08T00:47:15.553385Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"tensor = torch.tensor([[127,127,127,127],[127,0,0,127],[127,255,255,127],[127,127,127,127]])\nx = CFG.to_numpy(tensor)\nx","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:47:15.557232Z","iopub.status.idle":"2022-04-08T00:47:15.557721Z","shell.execute_reply.started":"2022-04-08T00:47:15.557420Z","shell.execute_reply":"2022-04-08T00:47:15.557459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(x)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:47:15.559321Z","iopub.status.idle":"2022-04-08T00:47:15.559721Z","shell.execute_reply.started":"2022-04-08T00:47:15.559506Z","shell.execute_reply":"2022-04-08T00:47:15.559528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_from_tensor(tensor)","metadata":{"execution":{"iopub.status.busy":"2022-04-08T00:47:15.561139Z","iopub.status.idle":"2022-04-08T00:47:15.561548Z","shell.execute_reply.started":"2022-04-08T00:47:15.561313Z","shell.execute_reply":"2022-04-08T00:47:15.561336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}