{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport shutil\nimport copy\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score, accuracy_score\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import Adam\n\n\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nimport torch.nn.functional as F\n#import torchvision.transforms.functional as F\n#from torchvision.datasets import OxfordIIITPet\n\nfrom PIL import Image\nimport io\nfrom io import BytesIO \n\nimport cv2\n\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom albumentations import (\n    Compose, OneOf, Normalize, CenterCrop, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n    RandomBrightness, RandomContrast, RandomBrightnessContrast, RandomRotate90, ShiftScaleRotate, Cutout, \n    IAAAdditiveGaussianNoise, Transpose, HueSaturationValue, CoarseDropout,GridDropout\n    )\n\nfrom IPython.display import Image, display\nfrom tensorflow.keras.preprocessing.image import load_img\nimport PIL\nfrom PIL import Image as Im\nfrom PIL import ImageOps\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"2hbZj8CKoAc-","execution":{"iopub.status.busy":"2022-05-10T08:43:37.855661Z","iopub.execute_input":"2022-05-10T08:43:37.856345Z","iopub.status.idle":"2022-05-10T08:43:48.004381Z","shell.execute_reply.started":"2022-05-10T08:43:37.856231Z","shell.execute_reply":"2022-05-10T08:43:48.003536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configurations","metadata":{}},{"cell_type":"code","source":" class CFG:\n        BASE_PATH = '../input/oxfordiiitpet-dataset/'\n        IMAGE_PATH = '../input/oxfordiiitpet-dataset/images/images/'\n        ANNOTATION_PATH = '../input/oxfordiiitpet-dataset/annotations/annotations/'\n        \n        DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n        IMAGE_SIZE = 128\n        BATCH_SIZE = 64\n        \n        def to_numpy(tensor):\n            return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.008315Z","iopub.execute_input":"2022-05-10T08:43:48.008533Z","iopub.status.idle":"2022-05-10T08:43:48.027509Z","shell.execute_reply.started":"2022-05-10T08:43:48.008505Z","shell.execute_reply":"2022-05-10T08:43:48.025964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create DataFrame","metadata":{}},{"cell_type":"code","source":"all_df = pd.read_table(CFG.ANNOTATION_PATH+'list.txt',sep=' ',skiprows=5 )\nall_df = all_df.iloc[:,:4]\nall_df = all_df.set_axis(['image_name','id','species','breed'],axis=1)\nall_df","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.028715Z","iopub.execute_input":"2022-05-10T08:43:48.028979Z","iopub.status.idle":"2022-05-10T08:43:48.086602Z","shell.execute_reply.started":"2022-05-10T08:43:48.028943Z","shell.execute_reply":"2022-05-10T08:43:48.085745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df.groupby(\"id\").count()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.090383Z","iopub.execute_input":"2022-05-10T08:43:48.090596Z","iopub.status.idle":"2022-05-10T08:43:48.114492Z","shell.execute_reply.started":"2022-05-10T08:43:48.090572Z","shell.execute_reply":"2022-05-10T08:43:48.113755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEBUG = False\nif DEBUG:\n    all_df = all_df.sample(frac = 0.01).reset_index(drop = True)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.117554Z","iopub.execute_input":"2022-05-10T08:43:48.117756Z","iopub.status.idle":"2022-05-10T08:43:48.125198Z","shell.execute_reply.started":"2022-05-10T08:43:48.117732Z","shell.execute_reply":"2022-05-10T08:43:48.124465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_df","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.127113Z","iopub.execute_input":"2022-05-10T08:43:48.127427Z","iopub.status.idle":"2022-05-10T08:43:48.141798Z","shell.execute_reply.started":"2022-05-10T08:43:48.127349Z","shell.execute_reply":"2022-05-10T08:43:48.141082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split train and validation 7:3","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(all_df, test_size = 0.3)\nprint(train_df.shape, valid_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.143551Z","iopub.execute_input":"2022-05-10T08:43:48.144105Z","iopub.status.idle":"2022-05-10T08:43:48.154247Z","shell.execute_reply.started":"2022-05-10T08:43:48.144037Z","shell.execute_reply":"2022-05-10T08:43:48.153347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.reset_index(drop=True)\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.1559Z","iopub.execute_input":"2022-05-10T08:43:48.156341Z","iopub.status.idle":"2022-05-10T08:43:48.177588Z","shell.execute_reply.started":"2022-05-10T08:43:48.156303Z","shell.execute_reply":"2022-05-10T08:43:48.176736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_df = valid_df.reset_index(drop=True)\nvalid_df","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.178891Z","iopub.execute_input":"2022-05-10T08:43:48.17932Z","iopub.status.idle":"2022-05-10T08:43:48.192517Z","shell.execute_reply.started":"2022-05-10T08:43:48.179281Z","shell.execute_reply":"2022-05-10T08:43:48.191472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize images","metadata":{}},{"cell_type":"code","source":"#nomal images\nimage = Im.open(CFG.IMAGE_PATH+all_df[\"image_name\"][0]+\".jpg\")\n#image = Im.open('../input/oxfordiiitpet-dataset/images/images/Abyssinian_10.jpg')\ndisplay(image)\ni = np.array(image)\ni.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.197639Z","iopub.execute_input":"2022-05-10T08:43:48.1986Z","iopub.status.idle":"2022-05-10T08:43:48.319325Z","shell.execute_reply.started":"2022-05-10T08:43:48.198564Z","shell.execute_reply":"2022-05-10T08:43:48.315892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mask image\n#mask_image = PIL.ImageOps.autocontrast(load_img('../input/oxfordiiitpet-dataset/annotations/annotations/trimaps/Abyssinian_10.png'))\nmask_image = PIL.ImageOps.autocontrast(load_img(CFG.ANNOTATION_PATH+'trimaps/'+all_df[\"image_name\"][0]+'.png'))\ndisplay(mask_image)\nrgb2gry = transforms.Grayscale()\nmask_images = mask_image.convert('L')\n#mask_image = mask_image.transpose(1,0,2)\n\nmask = np.array(mask_image)\nprint(mask.shape)\n#mask = mask.transpose(1,0,2)\n\nobj_ids = np.unique(mask)\nprint(obj_ids)\n\n# convert [0,127,255] to [0,1,2]\nmask[mask == 0] = 1\nmask[mask == 127] = 0\nmask[mask == 255] = 1\nprint(mask)\nprint(np.unique(mask))\n#obj_ids[:]\n#masks = mask == obj_ids[:,None,None]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.320689Z","iopub.execute_input":"2022-05-10T08:43:48.32096Z","iopub.status.idle":"2022-05-10T08:43:48.381119Z","shell.execute_reply.started":"2022-05-10T08:43:48.320926Z","shell.execute_reply":"2022-05-10T08:43:48.380214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(image))\nprint(type(mask_image))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.382748Z","iopub.execute_input":"2022-05-10T08:43:48.383263Z","iopub.status.idle":"2022-05-10T08:43:48.388974Z","shell.execute_reply.started":"2022-05-10T08:43:48.383222Z","shell.execute_reply":"2022-05-10T08:43:48.387844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# image and mask","metadata":{}},{"cell_type":"code","source":"def get_concat_h(im1, im2):\n    dst = Im.new('RGB', (im1.width + im2.width, im1.height))\n    dst.paste(im1, (0, 0))\n    dst.paste(im2, (im1.width, 0))\n    return dst\n\nget_concat_h(image, mask_image)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.390426Z","iopub.execute_input":"2022-05-10T08:43:48.391245Z","iopub.status.idle":"2022-05-10T08:43:48.491402Z","shell.execute_reply.started":"2022-05-10T08:43:48.391199Z","shell.execute_reply":"2022-05-10T08:43:48.490511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation function","metadata":{}},{"cell_type":"code","source":"def get_transform(data):\n    if data == 'train':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.HorizontalFlip(p=0.5),\n                #A.GridDropout(ratio=0.2, unit_size_min=None, unit_size_max=None, holes_number_x=5, holes_number_y=5, shift_x=0, shift_y=0, random_offset=False, fill_value=0, mask_fill_value=None, always_apply=False, p=0.5),\n                A.Normalize(),\n                ToTensorV2()\n            ])\n    elif data == 'valid':\n        return A.Compose([\n                A.Resize(CFG.IMAGE_SIZE,CFG.IMAGE_SIZE),\n                A.Normalize(),\n                ToTensorV2()\n            ])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.492906Z","iopub.execute_input":"2022-05-10T08:43:48.493733Z","iopub.status.idle":"2022-05-10T08:43:48.501689Z","shell.execute_reply.started":"2022-05-10T08:43:48.493691Z","shell.execute_reply":"2022-05-10T08:43:48.500934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(all_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.503165Z","iopub.execute_input":"2022-05-10T08:43:48.50403Z","iopub.status.idle":"2022-05-10T08:43:48.517763Z","shell.execute_reply.started":"2022-05-10T08:43:48.503992Z","shell.execute_reply":"2022-05-10T08:43:48.516698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#confirm path for dataset class\nimage_path = CFG.IMAGE_PATH\nmask_path = CFG.ANNOTATION_PATH\nprint(os.path.join(image_path, all_df[\"image_name\"][0]+'.jpg'))\nprint(os.path.join(mask_path, 'trimaps/'+all_df[\"image_name\"][0]+'.png'))","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.520463Z","iopub.execute_input":"2022-05-10T08:43:48.521325Z","iopub.status.idle":"2022-05-10T08:43:48.530278Z","shell.execute_reply.started":"2022-05-10T08:43:48.521284Z","shell.execute_reply":"2022-05-10T08:43:48.529028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, image_paths, mask_paths, df, transforms=None):\n        self.image_paths = image_paths\n        self.mask_paths = mask_paths\n        self.df = df\n        self.image_names = df[\"image_name\"]\n        self.transforms = transforms\n        \n    def __len__(self):\n        #print(len(self.df))\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        # get path\n        image_name = self.image_names[idx]\n        image_path = os.path.join(self.image_paths, image_name+'.jpg')\n        mask_path = os.path.join(self.mask_paths, 'trimaps/'+image_name+'.png')\n        #print(image_path,mask_path)\n        #open image\n        image = Im.open(image_path)\n        mask_images = PIL.ImageOps.autocontrast(load_img(mask_path))\n        rgb2gry = transforms.Grayscale()\n        mask_images = rgb2gry(mask_images)\n        #PIL to numpy\n        image = np.array(image)\n        image = image[:,:,:3]#remove some of alpha channels\n\n        mask_images = np.array(mask_images)\n\n        #convert [0,127,255] -> [0,1,2] #0が黒→物体内部、127がグレー→背景、255が白→物体輪郭\n        mask_images[mask_images == 0] = 0\n        mask_images[mask_images == 127] = 1\n        mask_images[mask_images == 255] = 2\n        #print(mask_images)\n\n        obj_ids = np.unique(mask_images)\n        \n        if self.transforms:\n            augmented = self.transforms(image=image,mask=mask_images)\n            image,mask = augmented['image'],augmented['mask']\n            #print(image.shape,mask.shape)\n\n        mask  = mask.unsqueeze(0)\n\n\n        return image,mask, image_path, mask_path","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.531557Z","iopub.execute_input":"2022-05-10T08:43:48.533912Z","iopub.status.idle":"2022-05-10T08:43:48.545685Z","shell.execute_reply.started":"2022-05-10T08:43:48.533882Z","shell.execute_reply":"2022-05-10T08:43:48.544975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    train_df,\n    transforms = get_transform(data='train'),\n)\nvalid_dataset = TrainDataset(\n    CFG.IMAGE_PATH,\n    CFG.ANNOTATION_PATH,\n    valid_df,\n    transforms = get_transform(data='valid'),\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.547132Z","iopub.execute_input":"2022-05-10T08:43:48.547826Z","iopub.status.idle":"2022-05-10T08:43:48.558795Z","shell.execute_reply.started":"2022-05-10T08:43:48.547788Z","shell.execute_reply":"2022-05-10T08:43:48.557852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CPUのコア数を確認\nimport os\nos.cpu_count()  # コア数","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.562242Z","iopub.execute_input":"2022-05-10T08:43:48.56379Z","iopub.status.idle":"2022-05-10T08:43:48.57252Z","shell.execute_reply.started":"2022-05-10T08:43:48.563755Z","shell.execute_reply":"2022-05-10T08:43:48.57157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True,drop_last=True)\ntrain_dataset[0][2:]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.573992Z","iopub.execute_input":"2022-05-10T08:43:48.574858Z","iopub.status.idle":"2022-05-10T08:43:48.625584Z","shell.execute_reply.started":"2022-05-10T08:43:48.574796Z","shell.execute_reply":"2022-05-10T08:43:48.624676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_loader = DataLoader(valid_dataset, CFG.BATCH_SIZE, shuffle = False, num_workers=os.cpu_count(), pin_memory=True,drop_last=True)\nvalid_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.627078Z","iopub.execute_input":"2022-05-10T08:43:48.627696Z","iopub.status.idle":"2022-05-10T08:43:48.724416Z","shell.execute_reply.started":"2022-05-10T08:43:48.627602Z","shell.execute_reply":"2022-05-10T08:43:48.72327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_f_image_path, best_f_mask_path = valid_dataset[0][2:]\nbest_f_image_path, best_f_mask_path","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.726019Z","iopub.execute_input":"2022-05-10T08:43:48.726326Z","iopub.status.idle":"2022-05-10T08:43:48.744989Z","shell.execute_reply.started":"2022-05-10T08:43:48.726289Z","shell.execute_reply":"2022-05-10T08:43:48.744175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define U-Net model","metadata":{}},{"cell_type":"markdown","source":"## part of U-Net models","metadata":{}},{"cell_type":"code","source":"!pip install -q segmentation_models_pytorch\nimport segmentation_models_pytorch as smp\n\ndef build_model():\n    model = smp.Unet(\n        encoder_name='mobilenet_v2',      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n        in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n        classes=3,        # model output channels (number of classes in your dataset)\n        activation=None,\n    )\n    model.to(CFG.DEVICE)\n    return model\n\ndef load_model(path):\n    model = build_model()\n    model.load_state_dict(torch.load(path))\n    model.eval()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:43:48.746483Z","iopub.execute_input":"2022-05-10T08:43:48.747147Z","iopub.status.idle":"2022-05-10T08:44:04.006612Z","shell.execute_reply.started":"2022-05-10T08:43:48.747109Z","shell.execute_reply":"2022-05-10T08:44:04.00576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#pytorch official\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels, mid_channels=None):\n        super().__init__()\n        if not mid_channels:\n            mid_channels = out_channels\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1,bias=False),\n            nn.BatchNorm2d(mid_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    def forward(self, x):\n        return self.double_conv(x)\n\nclass Down(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.maxpool_conv = nn.Sequential(\n            nn.MaxPool2d(2),\n            DoubleConv(in_channels, out_channels)\n        )\n    def forward(self, x):\n        return self.maxpool_conv(x)\n\nclass Up(nn.Module):\n    def __init__(self, in_channels, out_channels, bilinear=True):\n        super().__init__()\n        if bilinear:\n            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n        else:\n            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n            self.conv = DoubleConv(in_channels, out_channels)\n        #self.up = nn.ConvTranspose2d(in_channels, in_channels//2, kernel_size=2, stride=2)\n        #self.conv = DoubleConv(in_channels, out_channels)\n        \n    def forward(self, x1,x2):\n        x1 = self.up(x1)\n        \n        diffY = x2.size()[2] - x1.size()[2]\n        diffX = x2.size()[3] - x1.size()[3]\n        \n        x1 = F.pad(x1, [diffX // 2, diffX - diffX //2,\n                        diffY // 2, diffY - diffY //2])\n        \n        x = torch.cat([x2,x1],dim=1)\n        return self.conv(x)\n    \nclass OutConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(OutConv, self).__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        return self.conv(x)","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:36:38.366868Z","iopub.execute_input":"2022-05-04T09:36:38.367459Z","iopub.status.idle":"2022-05-04T09:36:38.382715Z","shell.execute_reply.started":"2022-05-04T09:36:38.367423Z","shell.execute_reply":"2022-05-04T09:36:38.381954Z"}}},{"cell_type":"markdown","source":"## main part of U-Net","metadata":{}},{"cell_type":"markdown","source":"#pytorch official\nclass UNet(nn.Module):\n    def __init__(self, n_channels, n_classes,bilinear=False):\n        super(UNet, self).__init__()\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.bilinear = bilinear\n        \n        self.inc = DoubleConv(n_channels, 64)\n        self.down1 = Down(64,128)\n        self.down2 = Down(128,256)\n        self.down3 = Down(256,512)\n        factor = 2 if bilinear else 1\n        self.down4 = Down(512,1024 // factor)\n        self.up1 = Up(1024,512 // factor, bilinear)\n        self.up2 = Up(512,256 // factor, bilinear)\n        self.up3 = Up(256,128 // factor, bilinear)\n        self.up4 = Up(128,64, bilinear)\n        self.outc = OutConv(64,n_classes)\n    \n    def forward(self, x):\n        x1 = self.inc(x)\n        x2 = self.down1(x1)\n        x3 = self.down2(x2)\n        x4 = self.down3(x3)\n        x5 = self.down4(x4)\n        x = self.up1(x5,x4)\n        x = self.up2(x,x3)\n        x = self.up3(x,x2)\n        x = self.up4(x,x1)\n        logits = self.outc(x)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-05-04T09:36:38.434021Z","iopub.execute_input":"2022-05-04T09:36:38.434724Z","iopub.status.idle":"2022-05-04T09:36:38.44484Z","shell.execute_reply.started":"2022-05-04T09:36:38.434687Z","shell.execute_reply":"2022-05-04T09:36:38.444113Z"}}},{"cell_type":"markdown","source":"# Custom metrics","metadata":{}},{"cell_type":"markdown","source":"## Dice","metadata":{}},{"cell_type":"code","source":"def Dice_Coeff(x,y,flag):\n    DICE = []\n    #x:predmask, y:truemask\n    x = CFG.to_numpy(x)\n    y = CFG.to_numpy(y)\n    x1 = copy.copy(x)\n    y1 = copy.copy(y)\n    x2 = copy.copy(x)\n    y2 = copy.copy(y)\n    x3 = copy.copy(x)\n    y3 = copy.copy(y)\n    \n    if flag == 1:#foreground\n        x1[x1==0] = 3\n        y1[y1==0] = 3\n        x1[x1==1] = 0\n        y1[y1==1] = 0\n        x1[x1==2] = 0\n        y1[y1==2] = 0\n        x1[x1==3] = 1\n        y1[y1==3] = 1\n        x1 = torch.tensor(x1)\n        y1 = torch.tensor(y1)\n        \n        #Foreground = []\n        inter = x1&y1\n        for i in range(CFG.BATCH_SIZE):\n            intersection = torch.sum(inter[i])\n            dice = (2*intersection)/(torch.sum(x1[i])+torch.sum(y1[i]))                \n            DICE.append(dice)\n        \n    elif flag == 2:#background\n        x2[x2==1] = 1\n        y2[y2==1] = 1\n        x2[x2==2] = 0\n        y2[y2==2] = 0\n        x2[x2==0] = 0\n        y2[y2==0] = 0\n        x2 = torch.tensor(x2)\n        y2 = torch.tensor(y2)\n\n        #Background = []\n        inter = x2&y2\n        for i in range(CFG.BATCH_SIZE):\n            intersection = torch.sum(inter[i])\n            dice = (2*intersection)/(torch.sum(x2[i])+torch.sum(y2[i]))\n            DICE.append(dice)\n            \n    elif flag == 3:#border\n        x3[x3==1] = 0\n        y3[y3==1] = 0\n        x3[x3==2] = 1\n        y3[y3==2] = 1\n        x3[x3==0] = 0\n        y3[y3==0] = 0\n        x3 = torch.tensor(x3)\n        y3 = torch.tensor(y3)\n\n        #Border = []\n        inter = x3&y3\n        for i in range(CFG.BATCH_SIZE):\n            intersection = torch.sum(inter[i])\n            #dice = (2*intersection)/(CFG.IMAGE_SIZE*CFG.IMAGE_SIZE+CFG.IMAGE_SIZE*CFG.IMAGE_SIZE)\n            dice = (2*intersection)/(torch.sum(x3[i])+torch.sum(y3[i]))\n            DICE.append(dice)\n\n    return DICE","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:04.023569Z","iopub.execute_input":"2022-05-10T08:44:04.023861Z","iopub.status.idle":"2022-05-10T08:44:04.04078Z","shell.execute_reply.started":"2022-05-10T08:44:04.023795Z","shell.execute_reply":"2022-05-10T08:44:04.039903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ASSD medpy","metadata":{}},{"cell_type":"code","source":"!pip install libboost-python-dev build-essential\n!pip install medpy","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:04.04198Z","iopub.execute_input":"2022-05-10T08:44:04.042291Z","iopub.status.idle":"2022-05-10T08:44:23.746077Z","shell.execute_reply.started":"2022-05-10T08:44:04.042255Z","shell.execute_reply":"2022-05-10T08:44:23.745144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import medpy.metric.binary","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:23.749722Z","iopub.execute_input":"2022-05-10T08:44:23.750035Z","iopub.status.idle":"2022-05-10T08:44:23.761353Z","shell.execute_reply.started":"2022-05-10T08:44:23.750001Z","shell.execute_reply":"2022-05-10T08:44:23.760542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#使ってない\nimport numpy as np\nfrom scipy.ndimage import _ni_support\nfrom scipy.ndimage.morphology import distance_transform_edt, binary_erosion, generate_binary_structure\nfrom abc import ABC\nclass EvaluationHelper(ABC):\n\n    @classmethod\n    def and_assd(cls, result: np.ndarray, reference: np.ndarray, num):\n        ASSD = []\n        \n        result = CFG.to_numpy(result)\n        reference = CFG.to_numpy(reference)\n        \n        result1 = copy.copy(result)\n        reference1 = copy.copy(reference)\n        \n        result2 = copy.copy(result)\n        reference2 = copy.copy(reference)\n        \n        result3 = copy.copy(result)\n        reference3 = copy.copy(reference)\n        \n        if num==1:#foreground\n            result1[result1==0] = 3\n            reference1[reference1==0] = 3\n            result1[result1==1] = 0\n            reference1[reference1==1] = 0\n            result1[result1==2] = 0\n            reference1[reference1==2] = 0\n            result1[result1==3] = 1\n            reference1[reference1==3] = 1\n\n            for i in range(CFG.BATCH_SIZE):\n                assd = EvaluationHelper.assd(result1[i], reference1[i])\n                print(f'1:{assd}')\n                ASSD.append(assd)\n            \n        elif num==2:#background\n            result2[result2==1] = 1\n            reference2[reference2==1] = 1\n            result2[result2==2] = 0\n            reference2[reference2==2] = 0\n            result2[result2==0] = 0\n            reference2[reference2==0] = 0\n            \n            assd = EvaluationHelper.assd(result2, reference2)\n            print(f'2:{assd}')\n            ASSD.append(assd)\n        else:#border\n            result3[result3==1] = 0\n            reference3[reference3==1] = 0\n            result3[result3==2] = 1\n            reference3[reference3==2] = 1\n            result3[result3==0] = 0\n            reference3[reference3==0] = 0\n            assd = EvaluationHelper.assd(result3, reference3)\n            print(f'3: {assd}')\n            ASSD.append(assd)\n\n            \n        return ASSD\n\n    @classmethod\n    def assd(cls,\n             result: np.ndarray,\n             reference: np.ndarray,\n             voxelspacing=None,\n             connectivity=1) -> float:\n        \n        assd = np.mean(\n            (cls.asd(result, reference, voxelspacing, connectivity),\n             cls.asd(result, reference, voxelspacing, connectivity)))\n        #print(f'assd : {assd}')\n        return assd\n\n    @classmethod\n    def asd(cls, result, reference, voxelspacing=None, connectivity=1):\n        \n        sds = cls.__surface_distances(result, reference, voxelspacing, connectivity)\n        asd = sds.mean()\n        #(f'asd : {asd}')\n        return asd\n\n    @staticmethod\n    def __surface_distances(result, reference, voxelspacing=None, connectivity=1):\n        \"\"\"\n        https://loli.github.io/medpy/_modules/medpy/metric/binary.html\n        The distances between the surface voxel of binary objects in result and their\n        nearest partner surface voxel of a binary object in reference.\n        \"\"\"\n        result = np.atleast_1d(result.astype(bool))\n        reference = np.atleast_1d(reference.astype(bool))\n        if voxelspacing is not None:\n            voxelspacing = _ni_support._normalize_sequence(voxelspacing, result.ndim)\n            voxelspacing = np.asarray(voxelspacing, dtype=np.float64)\n            if not voxelspacing.flags.contiguous:\n                voxelspacing = voxelspacing.copy()\n\n        # binary structure\n        footprint = generate_binary_structure(result.ndim, connectivity)\n\n        # test for emptiness\n        if 0 == np.count_nonzero(result):\n            raise RuntimeError('The first supplied array does not contain any binary object.')\n        if 0 == np.count_nonzero(reference):\n            raise RuntimeError('The second supplied array does not contain any binary object.')\n\n            # extract only 1-pixel border line of objects\n        result_border = result ^ binary_erosion(result, structure=footprint, iterations=1)\n        reference_border = reference ^ binary_erosion(reference, structure=footprint, iterations=1)\n\n        # compute average surface distance\n        # Note: scipys distance transform is calculated only inside the borders of the\n        #       foreground objects, therefore the input has to be reversed\n        dt = distance_transform_edt(~reference_border, sampling=voxelspacing)\n        sds = dt[result_border]\n        #print(f'sds : {sds}')\n        return sds","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:23.76961Z","iopub.execute_input":"2022-05-10T08:44:23.769865Z","iopub.status.idle":"2022-05-10T08:44:23.799308Z","shell.execute_reply.started":"2022-05-10T08:44:23.769806Z","shell.execute_reply":"2022-05-10T08:44:23.798052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ASSD original","metadata":{}},{"cell_type":"code","source":"import scipy\nfrom scipy.ndimage import _ni_support\nfrom scipy.ndimage.morphology import distance_transform_edt, binary_erosion, generate_binary_structure\n\ndef surface_distance(pred_mask,mask, connectivity=1):\n    pred_mask = np.atleast_1d(pred_mask.astype(np.bool_))\n    mask = np.atleast_1d(mask.astype(np.bool_))\n    conn = scipy.ndimage.morphology.generate_binary_structure(pred_mask.ndim,connectivity)\n    pred_mask_surface = pred_mask ^ scipy.ndimage.morphology.binary_erosion(pred_mask,structure=conn)\n    mask_surface = mask ^ scipy.ndimage.morphology.binary_erosion(mask,structure=conn)\n    dt = scipy.ndimage.morphology.distance_transform_edt(~mask_surface)\n    surface_distance = dt[pred_mask_surface]\n    return surface_distance, pred_mask_surface,mask_surface","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def avarage_symmetric_surface_distance(pred_mask,mask):\n    pred_mask_surface_distance,pred_mask_surface1,mask_surface1 = surface_distance(pred_mask,mask)\n    mask_surface_distance,mask_surface2,pred_mask_surface2 = surface_distance(mask,pred_mask)\n    pred_mask_asd = pred_mask_surface_distance.mean()\n    mask_asd = mask_surface_distance.mean()\n    pred_mask_surface = pred_mask_surface1.astype(np.int_)\n    mask_surface = mask_surface1.astype(np.int_)\n    \n    try:\n        assd = np.nanmean((pred_mask_asd,mask_asd))\n    \n    except ZeroDivisionError:\n        assd = 0.0\n    \n    #return assd,pred_mask_surface,mask_surface\n    return assd","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize image (input and mask)","metadata":{}},{"cell_type":"code","source":"def show_pred_mask(original,true_tensor,out_tensor,cnt):\n        unnormalize = transforms.Normalize(\n        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n        std=[1/0.229, 1/0.224, 1/0.255]\n        )\n        original = unnormalize(original)\n\n        y = CFG.to_numpy(true_tensor)\n        z = CFG.to_numpy(out_tensor)\n\n        original = original.permute(2,1,0)\n        original = CFG.to_numpy(original)\n        original = np.rot90(original)\n        original = np.flipud(original)\n        \n        #convert [0,127,255] -> [0,1,2] #0が黒→物体内部、127がグレー→背景、255が白→物体輪郭\n        #mask_images[mask_images == 127] = 1\n        #mask_images[mask_images == 255] = 2\n\n        y[y==0] = 255\n        y[y==1] = 127\n        y[y==2] = 0\n\n        z[z==0] = 255\n        z[z==1] = 127\n        z[z==2] = 0\n\n        n_data = 3\n        row=1\n        col=3\n        \n        fig, ax = plt.subplots(nrows=row, ncols=col,figsize=(15,18))\n        #input image\n        ax[0].imshow(original)\n        #truth mask\n        ax[1].imshow(y,cmap='Greys')\n        #pred mask\n        ax[2].imshow(z,cmap='Greys')\n        plt.show()\n        \n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:23.801948Z","iopub.execute_input":"2022-05-10T08:44:23.802212Z","iopub.status.idle":"2022-05-10T08:44:23.811208Z","shell.execute_reply.started":"2022-05-10T08:44:23.802176Z","shell.execute_reply":"2022-05-10T08:44:23.810232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save best,median,worst tensor\n* original tensor\n* pred tensor\n* true tensor","metadata":{}},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import statistics\nplot_train_loss = []\nplot_train_assd1 = []\nplot_train_assd2 = []\nplot_train_assd3 = []\nplot_train_dice1 = []\nplot_train_dice2 = []\nplot_train_dice3 = []\n\nplot_valid_loss = []\nplot_valid_assd1 = []\nplot_valid_assd2 = []\nplot_valid_assd3 = []\nplot_valid_dice1 = []\nplot_valid_dice2 = []\nplot_valid_dice3 = []\n\nL_t = []\nL_v = []\n\nA1_t = []\nA1_v = []\n\nA2_t = []\nA2_v = []\n\nA3_t = []\nA3_v = []\n\nD1_t = []\nD1_v = []\n\nD2_t = []\nD2_v = []\n\nD3_t = []\nD3_v = []\nA1 = []\nA2 = []\nA3 = []\n\n\n\ndef training_model(model, datasets, dataloaders, criterion, optimizer, num_epochs, device):\n    best_loss = 2.0\n    best_f_dice = 0.0\n    worst_loss = 0.0\n    \n    worst_f_dice = 1.0\n    median_loss = 0.0\n    median_f_dice = 0.0\n    \n    best_b_dice = 0.0\n    worst_b_dice = 1.0\n    median_b_dice = 0.0\n    \n    best_n_dice = 0.0\n    worst_n_dice = 1.0\n    median_n_dice = 0.0\n    #scaler = GradScaler()\n    \n    max_value = 0\n    min_value = 10**9\n    med_value = 0\n    \n    medlist = []\n    med_ori = []\n    med_pre = []\n    med_tru = []\n    \n    B = 0\n    \n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print('-'*10)\n        \n        for phase in ['train','valid']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n                \n            running_loss = 0.0\n            running_assd1 = 0.0\n            running_assd2 = 0.0\n            running_assd3 = 0.0\n            running_dice1 = 0.0\n            running_dice2 = 0.0\n            running_dice3 = 0.0\n                \n            stream = tqdm(dataloaders[phase])\n            for cnt, (inputs, masks,im_path,ms_path) in enumerate(stream, start=1):\n                total_value = []\n\n                original = inputs\n                inputs = inputs.to(device=CFG.DEVICE,dtype=torch.float32)\n                masks = masks.to(device=CFG.DEVICE,dtype=torch.long)\n                optimizer.zero_grad()\n                \n                #with autocast():\n                with torch.set_grad_enabled(phase=='train'):\n                    model = model.to(CFG.DEVICE)\n                    outputs = model(inputs)\n                    #print(outputs.shape)\n                    \n                    pred_masks = torch.argmax(outputs, dim=1)\n                    #print(pred_masks.shape,masks.shape)\n                    \n                    masks =  masks.squeeze(1)\n                    #print(pred_masks.shape,masks.shape)\n                    \n                    loss = criterion(outputs, masks)\n                    #print(loss)\n                    \n                    num = 1\n                    #assd1 = EvaluationHelper.and_assd(ch,masks,num)\n                    #assd2 = EvaluationHelper.and_assd(ch,masks,num+1)\n                    #assd3 = EvaluationHelper.and_assd(ch,masks,num+2)\n                    \n                    pred_masks = CFG.to_numpy(pred_masks)\n                    masks = CFG.to_numpy(masks)\n                    #print(np.unique(pred_masks),np.unique(masks))\n\n                    ch1 = copy.copy(pred_masks)\n                    masks1 = copy.copy(masks)\n                    ch1[ch1==0] = 3\n                    masks1[masks1==0] = 3\n                    ch1[ch1==1] = 0\n                    masks1[masks1==1] = 0\n                    ch1[ch1==2] = 0\n                    masks1[masks1==2] = 0\n                    ch1[ch1==3] = 1\n                    masks1[masks1==3] = 1\n                    #print(np.unique(ch1),np.unique(masks1))\n                    \n                    ch2 = copy.copy(pred_masks)\n                    masks2 = copy.copy(masks)\n                    ch2[ch2==1] = 1\n                    masks2[masks2==1] = 1\n                    ch2[ch2==2] = 0\n                    masks2[masks2==2] = 0\n                    ch2[ch2==0] = 0\n                    masks2[masks2==0] = 0\n                    #print(np.unique(ch2),np.unique(masks2))\n\n                    ch3 = copy.copy(pred_masks)\n                    masks3 = copy.copy(masks)\n                    ch3[ch3==1] = 0\n                    masks3[masks3==1] = 0\n                    ch3[ch3==2] = 1\n                    masks3[masks3==2] = 1\n                    ch3[ch3==0] = 0\n                    masks3[masks3==0] = 0\n                    #print(np.unique(ch3),np.unique(masks3))\n                    \n                    assd1 = 0\n                    assd2 = 0\n                    assd3 = 0\n                    n1 = 0\n                    n2 = 0\n                    n3 = 0\n                    #print(pred_masks.shape,masks.shape)\n                    #print(ch1.shape,masks1.shape)\n                    #print(ch2.shape,masks2.shape)\n                    #print(ch3.shape,masks3.shape)\n                    for i in range(CFG.BATCH_SIZE):\n                        assd1 = avarage_symmetric_surface_distance(ch1[i],masks1[i])\n                        if phase == 'valid':\n                            A1.append(assd1)\n                        #print(f'assd1 : {assd1}')\n                    for i in range(CFG.BATCH_SIZE):\n                        assd2 = avarage_symmetric_surface_distance(ch2[i],masks2[i]) \n                        if phase == 'valid':\n                            A2.append(assd2)\n                        #print(f'assd2 : {assd2}')\n                    for i in range(CFG.BATCH_SIZE):\n                        assd3 = avarage_symmetric_surface_distance(ch3[i],masks3[i])\n                        if phase == 'valid':\n                            A3.append(assd3)\n                        #print(f'assd3 : {assd3}')\n                    \n                            \n                    #running_assd1 += assd1#64データ分毎回足す\n                    #running_assd2 += assd2\n                    #running_assd3 += assd3\n                    #print(assd1/CFG.BATCH_SIZE,assd2/CFG.BATCH_SIZE,assd3/CFG.BATCH_SIZE)\n                    #print(cnt,assd1,assd2,assd3)\n                    ch = torch.tensor(pred_masks)\n                    masks = torch.tensor(masks)\n                    flag = 1\n                    dice11 = sum(Dice_Coeff(ch,masks, flag))/CFG.BATCH_SIZE#return array(dice1,dice2,...,dice(batch_size))\n                    dice22 = sum(Dice_Coeff(ch,masks, flag+1))/CFG.BATCH_SIZE\n                    dice33 = sum(Dice_Coeff(ch,masks, flag+2))/CFG.BATCH_SIZE\n                    dice1 = Dice_Coeff(ch, masks,flag)\n                    dice2 = Dice_Coeff(ch, masks,flag+1)\n                    dice3 = Dice_Coeff(ch, masks, flag+2)\n\n                    for i in range(CFG.BATCH_SIZE):\n                        total_value.append((dice1[i]+dice2[i]+dice3[i]).item())\n\n                    #max dice\n                    sum_max = max(total_value)\n                    if sum_max > max_value:\n                        max_value = sum_max\n                        max_idx = total_value.index(max_value)\n                        max_ori = original[max_idx]\n                        max_pre = masks[max_idx]\n                        max_tru = ch[max_idx]\n                    \n                    #min dice\n                    sum_min = min(total_value)\n                    if sum_min < min_value:\n                        min_value = sum_min\n                        min_idx = total_value.index(min_value)\n                        min_ori = original[min_idx]\n                        min_pre = masks[min_idx]\n                        min_tru = ch[min_idx]\n                        \n                    #med dice\n                    total_value.append(0)\n                    sum_med = statistics.median(total_value)\n                    if sum_med > med_value:\n                        med_value = sum_med\n                        med_idx = total_value.index(med_value)\n                        med_ori = original[med_idx]\n                        med_pre = masks[med_idx]\n                        med_tru = ch[med_idx]\n\n                    running_loss += loss.item()\n                    #B += CFG.BATCH_SIZE\n                    \n                    #running_assd1 /= B\n                    #running_assd2 /= B\n                    #running_assd3 /= B\n                    \n                    #print(running_assd1,B)\n                    \n                    #running_assd1 += assd1/(CFG.BATCH_SIZE)\n                    #running_assd2 += assd2/(CFG.BATCH_SIZE)\n                    #running_assd3 += assd3/(CFG.BATCH_SIZE)\n                    running_dice1 += dice11\n                    running_dice2 += dice22\n                    running_dice3 += dice33\n                    #print(running_assd1,running_assd2,running_assd3)\n                    if phase =='train':\n                        L_t.append(loss.item())\n                        #A1_t.append(assd1/(CFG.BATCH_SIZE))\n                        #A2_t.append(assd2/(CFG.BATCH_SIZE))\n                        #A3_t.append(assd3/(CFG.BATCH_SIZE))\n                        D1_t.append(CFG.to_numpy(dice11))\n                        D2_t.append(CFG.to_numpy(dice22))\n                        D3_t.append(CFG.to_numpy(dice33))\n                    else:\n                        L_v.append(loss.item())\n                        #A1_v.append(assd1/(CFG.BATCH_SIZE))\n                        #A2_v.append(assd2/(CFG.BATCH_SIZE))\n                        #A3_v.append(assd3/(CFG.BATCH_SIZE))\n                        D1_v.append(CFG.to_numpy(dice11))\n                        D2_v.append(CFG.to_numpy(dice22))\n                        D3_v.append(CFG.to_numpy(dice33))\n\n                    if cnt-1 == 0:\n                        show_pred_mask(original[0],masks[0],ch[0],cnt)\n                        show_pred_mask(original[1],masks[1],ch[1],cnt)\n                    else:\n                        continue\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                        \n                        \n                    if phase == 'valid' and loss < best_loss:\n                        best_loss = loss\n                    if phase == 'valid' and loss > worst_loss:\n                        worst_loss = loss\n                        \n                        \n                    if phase == 'valid' and dice11 > best_f_dice:\n                        best_f_dice = dice11\n                        print(f'[Foreground] Best Dice Result at the moment EPOCH:{epoch+1} Dice:{best_f_dice}')\n\n                    if phase == 'valid' and dice11 < worst_f_dice:\n                        worst_f_dice = dice11\n                        print(f'[Foreground] Worst Dice Result at the moment EPOCH:{epoch+1} Dice:{worst_f_dice}')\n\n                        \n                    if phase == 'valid' and dice22 > best_b_dice:\n                        best_b_dice = dice22\n                        print(f'[Background] Best Dice Result at the moment EPOCH:{epoch+1} Dice:{best_b_dice}')\n\n                    if phase == 'valid' and dice22 < worst_b_dice:\n                        worst_b_dice = dice22\n                        print(f'[Background] Worst Dice Result at the moment EPOCH:{epoch+1} Dice:{worst_b_dice}')\n                        \n                        \n                    if phase == 'valid' and dice33 > best_n_dice:\n                        best_n_dice = dice33\n                        print(f'[Border] Best Border Dice Result at the moment EPOCH:{epoch+1} Dice:{best_n_dice}')\n\n                    if phase == 'valid' and dice33 <worst_n_dice:\n                        worst_n_dice = dice33\n                        print(f'[Border] Worst Border Dice Result at the moment EPOCH:{epoch+1} Dice:{worst_n_dice}')\n\n            epoch_loss = running_loss/len(dataloaders[phase])\n            #epoch_assd1 = running_assd1/len(dataloaders[phase])\n            #epoch_assd2 = running_assd2/len(dataloaders[phase])\n            #epoch_assd3 = running_assd3/len(dataloaders[phase])\n            epoch_dice1 = running_dice1/len(dataloaders[phase])\n            epoch_dice2 = running_dice2/len(dataloaders[phase])\n            epoch_dice3 = running_dice3/len(dataloaders[phase])\n            \n            if phase == 'train':\n                plot_train_loss.append(epoch_loss)\n                #plot_train_assd1.append(epoch_assd1)\n                #plot_train_assd2.append(epoch_assd2)\n                #plot_train_assd3.append(epoch_assd3)\n                plot_train_dice1.append(epoch_dice1)\n                plot_train_dice2.append(epoch_dice2)\n                plot_train_dice3.append(epoch_dice3)\n            else:\n                plot_valid_loss.append(epoch_loss)\n                #plot_valid_assd1.append(epoch_assd1)\n                #plot_valid_assd2.append(epoch_assd2)\n                #plot_valid_assd3.append(epoch_assd3)\n                plot_valid_dice1.append(epoch_dice1)\n                plot_valid_dice2.append(epoch_dice2)\n                plot_valid_dice3.append(epoch_dice3)\n            \n            print(f'{phase} Loss: {epoch_loss} Foreground Dice: {epoch_dice1} Background Dice: {epoch_dice2} Border Dice: {epoch_dice3}')\n            #print(f'Foreground ASSD: {epoch_assd1} Background ASSD: {epoch_assd2} Border ASSD: {epoch_assd3}')\n            # Foreground ASSD: {epoch_assd1} Background ASSD: {epoch_assd2} Border ASSD: {epoch_assd3} \n            #print(f'{phase} Loss: {epoch_loss} Foreground Dice: {epoch_dice1} Background Dice: {epoch_dice2} Border Dice: {epoch_dice3}')\n        print()\n        \n    #max dice image\n    print(f'max dice image')\n    show_pred_mask(max_ori,max_pre,max_tru,cnt)\n    \n    #median dice image\n    #medlist.append(0)\n    #medice = statistics.median(medlist)\n    #med_idx = medlist.index(medice)\n    print(f'median dice image')\n    show_pred_mask(med_ori,med_pre,med_tru,cnt)\n    \n    #min dice image\n    print(f'min dice image')\n    show_pred_mask(min_ori,min_pre,min_tru,cnt)\n    \n    print(f'Best val Loss:{best_loss}')\n    print(f'Median val Loss:{(best_loss+worst_loss)/2}')\n    print(f'Worst val Loss:{worst_loss}')\n        \n    print(f'[Foreground] Best val Dice:{best_f_dice}　')\n    print(f'[Foreground] Median val Dice:{(best_f_dice+worst_f_dice)/2}　')\n    print(f'[Foreground] Worst val Dice:{worst_f_dice}　')\n    \n    print(f'[Background] Best val Dice:{best_b_dice}　')\n    print(f'[Background] Median val Dice:{(best_b_dice+worst_b_dice)/2}　')\n    print(f'[Background] Worst val Dice:{worst_b_dice}　')\n    \n    print(f'[Border] Best val Dice:{best_n_dice}　')\n    print(f'[Border] Median val Dice:{(best_n_dice+worst_n_dice)/2}　')\n    print(f'[Border] Worst val Dice:{worst_n_dice}　')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:23.834681Z","iopub.execute_input":"2022-05-10T08:44:23.83798Z","iopub.status.idle":"2022-05-10T08:44:23.89605Z","shell.execute_reply.started":"2022-05-10T08:44:23.837942Z","shell.execute_reply":"2022-05-10T08:44:23.89533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasets = {'train': train_dataset,\n            'valid': valid_dataset}\n\ndataloaders = {'train': train_loader,\n               'valid': valid_loader}\n#model = UNet(n_channels=3, n_classes=3)\nmodel = build_model()\n#optimizer = optim.SGD(model.paradfmeters(),lr=0.001,momentum=0.9)\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n#criterion = nn.BCELoss()\nnum_epochs = 50","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:23.897241Z","iopub.execute_input":"2022-05-10T08:44:23.897641Z","iopub.status.idle":"2022-05-10T08:44:31.138329Z","shell.execute_reply.started":"2022-05-10T08:44:23.897607Z","shell.execute_reply":"2022-05-10T08:44:31.137563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model = training_model(model,datasets, dataloaders, criterion, optimizer, num_epochs, CFG.DEVICE)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:31.139725Z","iopub.execute_input":"2022-05-10T08:44:31.140001Z","iopub.status.idle":"2022-05-10T08:44:46.14987Z","shell.execute_reply.started":"2022-05-10T08:44:31.139967Z","shell.execute_reply":"2022-05-10T08:44:46.148122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(A1),max(A2),max(A3)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.151393Z","iopub.status.idle":"2022-05-10T08:44:46.151949Z","shell.execute_reply.started":"2022-05-10T08:44:46.151666Z","shell.execute_reply":"2022-05-10T08:44:46.151694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot ASSD","metadata":{}},{"cell_type":"code","source":"data = (A1,A2,A3)\nfig,ax = plt.subplots()\nax.set_title('ASSD')\nax.set_xticklabels(['Foreground', 'Background', 'Border'])\nax.boxplot(data)\nplt.ylim([0, 150])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.15365Z","iopub.status.idle":"2022-05-10T08:44:46.155212Z","shell.execute_reply.started":"2022-05-10T08:44:46.15492Z","shell.execute_reply":"2022-05-10T08:44:46.15495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = (A1,A2,A3)\nfig,ax = plt.subplots()\nax.set_title('ASSD')\nax.set_xticklabels(['Foreground', 'Background', 'Border'])\nax.boxplot(data)\nplt.ylim([0, 40])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.156577Z","iopub.status.idle":"2022-05-10T08:44:46.157278Z","shell.execute_reply.started":"2022-05-10T08:44:46.157018Z","shell.execute_reply":"2022-05-10T08:44:46.157045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Dice","metadata":{}},{"cell_type":"code","source":"data = (list(np.array(D1_v)),list(np.array(D2_v)),list(np.array(D3_v)))\nfig,ax = plt.subplots()\nax.set_title('Dice')\nax.set_xticklabels(['Foreground', 'Background', 'Border'])\nax.boxplot(data)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.162738Z","iopub.status.idle":"2022-05-10T08:44:46.163471Z","shell.execute_reply.started":"2022-05-10T08:44:46.163195Z","shell.execute_reply":"2022-05-10T08:44:46.163222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = (list(np.array(D1_v)),list(np.array(D2_v)),list(np.array(D3_v)))\nfig,ax = plt.subplots()\nax.set_title('Dice')\nax.set_xticklabels(['Foreground', 'Background', 'Border'])\nax.boxplot(data)\nplt.ylim([0, 1.0])\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.164877Z","iopub.status.idle":"2022-05-10T08:44:46.165563Z","shell.execute_reply.started":"2022-05-10T08:44:46.165294Z","shell.execute_reply":"2022-05-10T08:44:46.16532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loss\nplt.title(\"Loss\",fontsize=18)\nplt.xlabel(\"Epoch\",fontsize=14)\nplt.ylabel(\"Loss\",fontsize=14)\n\nplt.ylim(0.4, 1.2)\nplt.xlim(0, num_epochs+1, 1)\n\nplt.xticks(np.arange(0, num_epochs+1, 1))\nplt.plot(range(1, num_epochs+1),plot_train_loss,label='Training Loss',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_loss,label='Validation Loss',marker ='o')\nplt.legend(frameon=False, fontsize=14)\n\nplt.show()\n\n#dice1\nplt.title(\"Dice Foreground\",fontsize=18)\nplt.xlabel(\"Epoch\",fontsize=14)\nplt.ylabel(\"Dice\",fontsize=14)\n\nplt.ylim(0.1,1.0)\nplt.xlim(0, num_epochs+1, 1)\n\nplt.xticks(np.arange(0, num_epochs+1, 1))\n#plt.plot(range(1, num_epochs+1),plot_train_dice1,label='Training Dice',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_dice1,label='Foreground Dice',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_dice2,label='Background Dice',marker ='o')\nplt.plot(range(1, num_epochs+1),plot_valid_dice3,label='border Dice',marker ='o')\nplt.legend(frameon=False, fontsize=14)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.170932Z","iopub.status.idle":"2022-05-10T08:44:46.171619Z","shell.execute_reply.started":"2022-05-10T08:44:46.171349Z","shell.execute_reply":"2022-05-10T08:44:46.171388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax = plt.subplots()\nbp = ax.boxplot(list(np.array_split(L_v, num_epochs)))\nplt.title('Loss')\nplt.ylabel('loss')\nplt.ylim([0.7, 1.2])\nplt.grid()","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.172917Z","iopub.status.idle":"2022-05-10T08:44:46.173588Z","shell.execute_reply.started":"2022-05-10T08:44:46.173327Z","shell.execute_reply":"2022-05-10T08:44:46.173352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 以下、確認コード","metadata":{}},{"cell_type":"code","source":"import torch\ntensorx = torch.tensor([[[1,0,1,1],[1,1,1,1],[1,0,0,1],[1,1,0,0]]])\ntensory = torch.tensor([[[1,0,0,1],[1,0,0,1],[1,1,0,1],[1,0,0,0]]])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.182403Z","iopub.status.idle":"2022-05-10T08:44:46.183072Z","shell.execute_reply.started":"2022-05-10T08:44:46.182823Z","shell.execute_reply":"2022-05-10T08:44:46.182863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = CFG.to_numpy(tensorx)\nY = CFG.to_numpy(tensory)\nX,Y","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.184331Z","iopub.status.idle":"2022-05-10T08:44:46.185027Z","shell.execute_reply.started":"2022-05-10T08:44:46.184752Z","shell.execute_reply":"2022-05-10T08:44:46.184777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X[X==0] = 1\nX","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.186295Z","iopub.status.idle":"2022-05-10T08:44:46.186965Z","shell.execute_reply.started":"2022-05-10T08:44:46.186708Z","shell.execute_reply":"2022-05-10T08:44:46.186732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import medpy\nans = medpy.metric.binary.assd(X,Y)\nans","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.188174Z","iopub.status.idle":"2022-05-10T08:44:46.188862Z","shell.execute_reply.started":"2022-05-10T08:44:46.188579Z","shell.execute_reply":"2022-05-10T08:44:46.188603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom scipy.ndimage import _ni_support\nfrom scipy.ndimage.morphology import distance_transform_edt, binary_erosion, generate_binary_structure\nfrom abc import ABC\nclass EvaluationHelper(ABC):\n\n    @classmethod\n    def and_assd(cls, result: np.ndarray, reference: np.ndarray):\n        assd = EvaluationHelper.assd(result, reference)\n            \n        return assd\n\n    @classmethod\n    def assd(cls,\n             result: np.ndarray,\n             reference: np.ndarray,\n             voxelspacing=None,\n             connectivity=1) -> float:\n        \n        assd = np.mean(\n            (cls.asd(result, reference, voxelspacing, connectivity),\n             cls.asd(reference, result, voxelspacing, connectivity)))\n        print(f'assd : {assd}')\n        return assd\n\n    @classmethod\n    def asd(cls, result, reference, voxelspacing=None, connectivity=1):\n        \n        sds = cls.__surface_distances(result, reference, voxelspacing, connectivity)\n        asd = sds.mean()\n        print(f'asd : {asd}')\n        return asd\n\n    @staticmethod\n    def __surface_distances(result, reference, voxelspacing=None, connectivity=1):\n        \"\"\"\n        https://loli.github.io/medpy/_modules/medpy/metric/binary.html\n        The distances between the surface voxel of binary objects in result and their\n        nearest partner surface voxel of a binary object in reference.\n        \"\"\"\n        result = np.atleast_1d(result.astype(bool))\n        reference = np.atleast_1d(reference.astype(bool))\n        if voxelspacing is not None:\n            voxelspacing = _ni_support._normalize_sequence(voxelspacing, result.ndim)\n            voxelspacing = np.asarray(voxelspacing, dtype=np.float64)\n            if not voxelspacing.flags.contiguous:\n                voxelspacing = voxelspacing.copy()\n\n        # binary structure\n        footprint = generate_binary_structure(result.ndim, connectivity)\n\n        # test for emptiness\n        if 0 == np.count_nonzero(result):\n            raise RuntimeError('The first supplied array does not contain any binary object.')\n        if 0 == np.count_nonzero(reference):\n            raise RuntimeError('The second supplied array does not contain any binary object.')\n\n            # extract only 1-pixel border line of objects\n        result_border = result ^ binary_erosion(result, structure=footprint, iterations=1)\n        reference_border = reference ^ binary_erosion(reference, structure=footprint, iterations=1)\n\n        # compute average surface distance\n        # Note: scipys distance transform is calculated only inside the borders of the\n        #       foreground objects, therefore the input has to be reversed\n        dt = distance_transform_edt(~reference_border, sampling=voxelspacing)\n        sds = dt[result_border]\n        print(f'sds : {sds}')\n        return sds","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.190224Z","iopub.status.idle":"2022-05-10T08:44:46.190912Z","shell.execute_reply.started":"2022-05-10T08:44:46.190644Z","shell.execute_reply":"2022-05-10T08:44:46.190669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assd = EvaluationHelper.and_assd(X,Y)","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.192199Z","iopub.status.idle":"2022-05-10T08:44:46.192904Z","shell.execute_reply.started":"2022-05-10T08:44:46.19263Z","shell.execute_reply":"2022-05-10T08:44:46.192655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def asd(cls, result, reference, voxelspacing=None, connectivity=1):\n        \n        sds = cls.__surface_distances(result, reference, voxelspacing, connectivity)\n        asd = sds.mean()\n        return asd","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.194182Z","iopub.status.idle":"2022-05-10T08:44:46.194865Z","shell.execute_reply.started":"2022-05-10T08:44:46.194587Z","shell.execute_reply":"2022-05-10T08:44:46.194612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"asd = r.mean()\nasd","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.196159Z","iopub.status.idle":"2022-05-10T08:44:46.196849Z","shell.execute_reply.started":"2022-05-10T08:44:46.196577Z","shell.execute_reply":"2022-05-10T08:44:46.196603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assd = asd.mean()\nassd","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.198093Z","iopub.status.idle":"2022-05-10T08:44:46.198733Z","shell.execute_reply.started":"2022-05-10T08:44:46.198493Z","shell.execute_reply":"2022-05-10T08:44:46.198518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntensorx = torch.tensor([[[1,0,1,1],[1,1,1,1],[1,0,0,1],[1,1,0,0]],[[1,0,1,0],[0,0,1,1],[0,0,0,1],[0,1,0,0]]])\ntensory = torch.tensor([[[1,0,0,1],[1,0,0,1],[1,1,0,1],[1,0,0,0]],[[0,1,0,1],[0,1,0,1],[0,1,1,1],[1,0,0,0]]])\n\nprint(f'pred {tensorx}')\nprint(f'true {tensory}')\nprint('------------------')\nprint(f'and {tensorx & tensory}')\nprint('------------------')\nprint(tensorx[0])\n\nprint(torch.sum(tensorx[0]))\n\nprint(torch.sum(tensorx[i])+sum(tensory[i]))\n\nd = []\ninter = tensorx&tensory\nprint(f'intersection {inter}')\n\nfor i in range(2):\n    intersection = torch.sum(inter[i])\n    print(intersection)\n    dice = (2*intersection)/(torch.sum(tensorx[i])+torch.sum(tensory[i]))\n    d.append(dice)\nprint(f'Dice{d}')","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.200012Z","iopub.status.idle":"2022-05-10T08:44:46.200692Z","shell.execute_reply.started":"2022-05-10T08:44:46.200436Z","shell.execute_reply":"2022-05-10T08:44:46.200462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nori=[]\npre=[]\nch=[]\n\ntensorx = torch.tensor([[[1,0,1,1],[1,1,1,1],[1,0,0,1],[1,1,0,0]],[[1,0,1,0],[0,0,1,1],[0,0,0,1],[0,1,0,0]]])\ntensory = torch.tensor([[[1,0,0,1],[1,0,0,1],[1,1,0,1],[1,0,0,0]],[[0,1,0,1],[0,1,0,1],[0,1,1,1],[1,0,0,0]]])\n\nori.append(tensorx)\nprint(ori)\nori.append(tensory)\nprint(ori)\n\nprint(ori[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.201997Z","iopub.status.idle":"2022-05-10T08:44:46.202686Z","shell.execute_reply.started":"2022-05-10T08:44:46.202421Z","shell.execute_reply":"2022-05-10T08:44:46.202449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l = [1,4,2,5]\nl","metadata":{"execution":{"iopub.status.busy":"2022-05-10T08:44:46.204962Z","iopub.status.idle":"2022-05-10T08:44:46.205685Z","shell.execute_reply.started":"2022-05-10T08:44:46.205426Z","shell.execute_reply":"2022-05-10T08:44:46.205453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}